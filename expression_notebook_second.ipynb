{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arazm21/ML-homework_4/blob/main/expression_notebook_second.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# loading the data and organising it"
      ],
      "metadata": {
        "id": "ShlkPaeoBQ3k"
      },
      "id": "ShlkPaeoBQ3k"
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "! mkdir ~/.kaggle\n",
        "!cp /content/drive/MyDrive/ColabNotebooks/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
        "! unzip challenges-in-representation-learning-facial-expression-recognition-challenge"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNNvBwljBQFE",
        "outputId": "30d91212-923f-43a5-f181-686af9137fc6"
      },
      "id": "dNNvBwljBQFE",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n",
            "Mounted at /content/drive\n",
            "Downloading challenges-in-representation-learning-facial-expression-recognition-challenge.zip to /content\n",
            " 77% 220M/285M [00:00<00:00, 830MB/s] \n",
            "100% 285M/285M [00:00<00:00, 776MB/s]\n",
            "Archive:  challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
            "  inflating: example_submission.csv  \n",
            "  inflating: fer2013.tar.gz          \n",
            "  inflating: icml_face_data.csv      \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fXPkihKllSZ",
        "outputId": "02731d4c-916b-4a90-efbc-f08827619049"
      },
      "id": "9fXPkihKllSZ",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.13.2)\n",
            "Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # Main PyTorch Library\n",
        "from torch import nn # Used for creating the layers and loss function\n",
        "from torch.optim import Adam # Adam Optimizer\n",
        "import torchvision.transforms as transforms # Transform function used to modify and preprocess all the images\n",
        "from torch.utils.data import Dataset, DataLoader # Dataset class and DataLoader for creating the objects\n",
        "from sklearn.preprocessing import LabelEncoder # Label Encoder to encode the classes from strings to numbers\n",
        "import matplotlib.pyplot as plt # Used for visualizing the images and plotting the training progress\n",
        "from PIL import Image # Used to read the images from the directory\n",
        "import pandas as pd # Used to read/create dataframes (csv) and process tabular data\n",
        "import numpy as np # preprocessing and numerical/mathematical operations\n",
        "import os # Used to read the images path from the directory\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # detect the GPU if any, if not use CPU, change cuda to mps if you have a mac\n",
        "print(\"Device available: \", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xib5nVmSLH0o",
        "outputId": "74e1cad1-e076-4856-e77c-807e8966a7fe"
      },
      "id": "xib5nVmSLH0o",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device available:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b5Ptu8H4Lzx6"
      },
      "id": "b5Ptu8H4Lzx6",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, Subset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "class ExpressionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, csv_file, indices=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "\n",
        "        if indices is not None:\n",
        "            self.data = self.data.iloc[indices].reset_index(drop=True)\n",
        "\n",
        "        self.images = self.data['pixels'].apply(\n",
        "            lambda x: np.fromstring(x, sep=' ', dtype=np.uint8).reshape(48, 48)\n",
        "        )\n",
        "        self.images = torch.tensor(np.stack(self.images.values), dtype=torch.float32).unsqueeze(1) / 255.0\n",
        "        self.labels = torch.tensor(self.data['emotion'].values, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx], self.labels[idx]\n",
        "\n",
        "\n",
        "def get_data(csv_file=\"train.csv\", slice=5, train=True, val_ratio=0.2, random_state=42):\n",
        "    # Load full train.csv data\n",
        "    full_data = pd.read_csv(csv_file)\n",
        "    indices = list(range(len(full_data)))\n",
        "\n",
        "    # Stratified split indices for train/validation\n",
        "    train_indices, val_indices = train_test_split(\n",
        "        indices,\n",
        "        test_size=val_ratio,\n",
        "        stratify=full_data['emotion'],\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Select which indices to use\n",
        "    selected_indices = train_indices if train else val_indices\n",
        "\n",
        "    # Create dataset with selected indices\n",
        "    dataset = ExpressionDataset(csv_file, indices=selected_indices)\n",
        "\n",
        "    # Slice dataset if requested\n",
        "    sliced_indices = list(range(0, len(dataset), slice))\n",
        "    return Subset(dataset, sliced_indices)\n",
        "\n",
        "\n",
        "def make_loader(dataset, batch_size):\n",
        "    loader = DataLoader(dataset=dataset,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=True,\n",
        "                        pin_memory=True,\n",
        "                        num_workers=2)\n",
        "    return loader\n"
      ],
      "metadata": {
        "id": "D1ye0F1iHqSC"
      },
      "id": "D1ye0F1iHqSC",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test that loading was ok"
      ],
      "metadata": {
        "id": "RsFhOzV_PHxI"
      },
      "id": "RsFhOzV_PHxI"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and create loader\n",
        "dataset = get_data(slice=1, train=False)\n",
        "loader = make_loader(dataset, batch_size=3)\n",
        "\n",
        "# Get a batch\n",
        "images, labels = next(iter(loader))\n",
        "\n",
        "# Class names from FER2013\n",
        "emotion_names = [\n",
        "    \"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"\n",
        "]\n",
        "\n",
        "# Plot the first 3 images\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(3):\n",
        "    plt.subplot(1, 3, i + 1)\n",
        "    plt.imshow(images[i][0], cmap='gray')\n",
        "    plt.title(f\"Label: {emotion_names[labels[i].item()]}\")\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "NvgplaWYHJX6",
        "outputId": "999df106-3702-466c-e084-49aa0876f71f"
      },
      "id": "NvgplaWYHJX6",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# connecting WANDB"
      ],
      "metadata": {
        "id": "XhwXYgieSf7u"
      },
      "id": "XhwXYgieSf7u"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Ensure deterministic behavior\n",
        "torch.backends.cudnn.deterministic = True\n",
        "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
        "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
        "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
        "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "zt2tymF2Se4p"
      },
      "id": "zt2tymF2Se4p",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "l2Op72b3SsY1",
        "outputId": "db7ae5c1-6cb2-4bd8-986a-25d6925f1e9f"
      },
      "id": "l2Op72b3SsY1",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marazm21\u001b[0m (\u001b[33marazm21-free-university-of-tbilisi-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ymLc1hz_XE5W"
      },
      "id": "ymLc1hz_XE5W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# different attempted architectures"
      ],
      "metadata": {
        "id": "FjvVv9RPXFbN"
      },
      "id": "FjvVv9RPXFbN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## convnet"
      ],
      "metadata": {
        "id": "jjCDTHA1RHhj"
      },
      "id": "jjCDTHA1RHhj"
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.nn as nn\n",
        "\n",
        "# class ConvNet_super_simple(nn.Module):\n",
        "#     def __init__(self, kernels, classes=7):\n",
        "#         super(ConvNet_super_simple, self).__init__()\n",
        "\n",
        "#         self.layer1 = nn.Sequential(\n",
        "#             nn.Conv2d(1, kernels[0], kernel_size=5, stride=1, padding=2),\n",
        "#             nn.ReLU(),\n",
        "#             nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "#         )\n",
        "#         self.layer2 = nn.Sequential(\n",
        "#             nn.Conv2d(kernels[0], kernels[1], kernel_size=5, stride=1, padding=2),\n",
        "#             nn.ReLU(),\n",
        "#             nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "#         )\n",
        "\n",
        "#         # Assuming 48x48 input, after two 2x2 poolings -> 48/2/2 = 12x12\n",
        "#         self.fc = nn.Linear(12 * 12 * kernels[1], classes)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         out = self.layer1(x)\n",
        "#         out = self.layer2(out)\n",
        "#         out = out.view(out.size(0), -1)\n",
        "#         out = self.fc(out)\n",
        "#         return out\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ConvNet_Improved(nn.Module):\n",
        "    def __init__(self, kernels, classes=7):\n",
        "        super(ConvNet_Improved, self).__init__()\n",
        "\n",
        "        # First conv block\n",
        "        self.conv1 = nn.Conv2d(1, kernels[0], kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(kernels[0])\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Second conv block\n",
        "        self.conv2 = nn.Conv2d(kernels[0], kernels[1], kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(kernels[1])\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Third conv block\n",
        "        self.conv3 = nn.Conv2d(kernels[1], kernels[2], kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(kernels[2])\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.dropout3 = nn.Dropout(0.4)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Assuming 48x48 input → 3 poolings: 48 → 24 → 12 → 6\n",
        "        self.flattened_dim = 6 * 6 * kernels[2]\n",
        "        self.fc = nn.Linear(self.flattened_dim, classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.dropout1(self.relu1(self.bn1(self.conv1(x)))))\n",
        "        x = self.pool2(self.dropout2(self.relu2(self.bn2(self.conv2(x)))))\n",
        "        x = self.pool3(self.dropout3(self.relu3(self.bn3(self.conv3(x)))))\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "RaFvctrZTf1t"
      },
      "id": "RaFvctrZTf1t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## resnet"
      ],
      "metadata": {
        "id": "cumrZOH9Sj1A"
      },
      "id": "cumrZOH9Sj1A"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsample=False, dropout_rate=0.2):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        stride = 2 if downsample else 1\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if downsample or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "        self.dropout = nn.Dropout2d(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.shortcut(x)\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out = self.dropout(out)  # ✅ Dropout after residual addition\n",
        "        out += identity\n",
        "        out = F.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class SimpleResNet15(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_classes=7, dropout_rate=0.34):\n",
        "        super(SimpleResNet15, self).__init__()\n",
        "\n",
        "        self.entry = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            ResidualBlock(64, 128, downsample=True, dropout_rate=dropout_rate),\n",
        "            ResidualBlock(128, 256, downsample=True, dropout_rate=dropout_rate),\n",
        "            ResidualBlock(256, 512, downsample=True, dropout_rate=dropout_rate),\n",
        "            ResidualBlock(512, 1024, downsample=True, dropout_rate=dropout_rate),\n",
        "            ResidualBlock(1024, 2048, downsample=True, dropout_rate=dropout_rate),\n",
        "            ResidualBlock(2048, 2048, downsample=True, dropout_rate=dropout_rate),\n",
        "            ResidualBlock(2048, 1024, downsample=True, dropout_rate=dropout_rate),\n",
        "            ResidualBlock(1024, 512, downsample=True, dropout_rate=dropout_rate),\n",
        "            ResidualBlock(512, 256, downsample=True, dropout_rate=dropout_rate),\n",
        "\n",
        "            ResidualBlock(512, 256, downsample=False, dropout_rate=dropout_rate),\n",
        "            ResidualBlock(256, 128, downsample=False, dropout_rate=dropout_rate),\n",
        "            ResidualBlock(128, 64, downsample=False, dropout_rate=dropout_rate),\n",
        "            ResidualBlock(64, 32, downsample=False, dropout_rate=dropout_rate)\n",
        "        )\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.entry(x)\n",
        "        x = self.layers(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)\n"
      ],
      "metadata": {
        "id": "PFYKchqhXTSt"
      },
      "id": "PFYKchqhXTSt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## googlenet(mini)"
      ],
      "metadata": {
        "id": "ltk-bzVKSnDU"
      },
      "id": "ltk-bzVKSnDU"
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# class MiniInception(nn.Module):\n",
        "#     def __init__(self, in_ch, c1, c3red, c3, pool_proj):\n",
        "#         super().__init__()\n",
        "#         # 1×1 branch\n",
        "#         self.b1 = nn.Conv2d(in_ch, c1, kernel_size=1)\n",
        "#         # 1×1 → 3×3 branch\n",
        "#         self.b2_1 = nn.Conv2d(in_ch, c3red, kernel_size=1)\n",
        "#         self.b2_2 = nn.Conv2d(c3red, c3,   kernel_size=3, padding=1)\n",
        "#         # pool → 1×1 branch\n",
        "#         self.b3_pool = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "#         self.b3_proj = nn.Conv2d(in_ch, pool_proj, kernel_size=1)\n",
        "#         self.bn = nn.BatchNorm2d(c1 + c3 + pool_proj)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         b1 = self.b1(x)\n",
        "#         b2 = self.b2_2(F.relu(self.b2_1(x)))\n",
        "#         b3 = self.b3_proj(self.b3_pool(x))\n",
        "#         out = torch.cat([b1, b2, b3], dim=1)\n",
        "#         return F.relu(self.bn(out))\n",
        "\n",
        "\n",
        "# class MiniGoogLeNet(nn.Module):\n",
        "#     def __init__(self, num_classes=7, aux_on=True):\n",
        "#         super().__init__()\n",
        "#         self.aux_on = aux_on\n",
        "\n",
        "#         # ---- stem ----\n",
        "#         self.stem = nn.Sequential(\n",
        "#             nn.Conv2d(1, 32, 3, padding=1),\n",
        "#             nn.BatchNorm2d(32), nn.ReLU(),\n",
        "#             nn.MaxPool2d(2, 2)  # 48→24\n",
        "#         )\n",
        "\n",
        "#         # ---- two Inception blocks ----\n",
        "#         self.inc1 = MiniInception(32, c1=16, c3red=16, c3=24, pool_proj=16)  # outputs 56\n",
        "#         self.inc2 = MiniInception(56, c1=32, c3red=24, c3=32, pool_proj=24)  # outputs 88\n",
        "\n",
        "#         # auxiliary head (after inc1)\n",
        "#         if aux_on:\n",
        "#             self.aux = nn.Sequential(\n",
        "#                 nn.AdaptiveAvgPool2d((4,4)),\n",
        "#                 nn.Conv2d(56, 32, 1), nn.ReLU(),\n",
        "#                 nn.Flatten(),\n",
        "#                 nn.Linear(32*4*4, 128), nn.ReLU(), nn.Dropout(0.5),\n",
        "#                 nn.Linear(128, num_classes)\n",
        "#             )\n",
        "\n",
        "#         # ---- classifier head ----\n",
        "#         self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "#         self.fc   = nn.Sequential(\n",
        "#             nn.Flatten(),\n",
        "#             nn.Dropout(0.5),\n",
        "#             nn.Linear(88, num_classes)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.stem(x)            # → [B,32,24,24]\n",
        "#         x1 = self.inc1(x)           # → [B,56,24,24]\n",
        "\n",
        "#         # you can still compute aux_out if you want,\n",
        "#         # but we won't return it so training code stays unchanged\n",
        "#         if self.training and self.aux_on:\n",
        "#             _ = self.aux(x1)\n",
        "\n",
        "#         x2 = F.max_pool2d(x1, 2, 2) # → [B,56,12,12]\n",
        "#         x2 = self.inc2(x2)          # → [B,88,12,12]\n",
        "\n",
        "#         x3 = self.pool(x2)          # → [B,88,1,1]\n",
        "#         main_out = self.fc(x3)      # → [B,num_classes]\n",
        "\n",
        "#         return main_out\n",
        "class MiniInception(nn.Module):\n",
        "    def __init__(self, in_ch, c1, c3red, c3, pool_proj, dropout=0.2):\n",
        "        super().__init__()\n",
        "        # 1×1 branch\n",
        "        self.b1 = nn.Conv2d(in_ch, c1, 1)\n",
        "        # 1×1 → 3×3 branch\n",
        "        self.b2_1 = nn.Conv2d(in_ch, c3red, 1)\n",
        "        self.b2_2 = nn.Conv2d(c3red, c3, 3, padding=1)\n",
        "        # pool → 1×1 branch\n",
        "        self.b3_pool = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "        self.b3_proj = nn.Conv2d(in_ch, pool_proj, 1)\n",
        "\n",
        "        self.bn = nn.BatchNorm2d(c1 + c3 + pool_proj)\n",
        "        self.dropout = nn.Dropout2d(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b1 = self.b1(x)\n",
        "        b2 = self.b2_2(F.relu(self.b2_1(x)))\n",
        "        b3 = self.b3_proj(self.b3_pool(x))\n",
        "        out = torch.cat([b1, b2, b3], dim=1)\n",
        "        out = F.relu(self.bn(out))\n",
        "        return self.dropout(out)\n",
        "\n",
        "\n",
        "class ComplexMiniGoogLeNet(nn.Module):\n",
        "    def __init__(self, num_classes=7, aux_on=True):\n",
        "        super().__init__()\n",
        "        self.aux_on = aux_on\n",
        "\n",
        "        # ── Stem ──\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32), nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)  # 48 → 24\n",
        "        )\n",
        "\n",
        "        # ── Inception Blocks ──\n",
        "        self.inc1 = MiniInception(32, c1=16, c3red=16, c3=32, pool_proj=16, dropout=0.2)   # →64 ch\n",
        "        self.inc2 = MiniInception(64, c1=24, c3red=24, c3=48, pool_proj=24, dropout=0.2)   # →96 ch\n",
        "        self.inc3 = MiniInception(96, c1=32, c3red=32, c3=64, pool_proj=32, dropout=0.3)   # →128 ch\n",
        "\n",
        "        # ── Auxiliary head (computed but not returned) ──\n",
        "        if aux_on:\n",
        "            self.aux = nn.Sequential(\n",
        "                nn.AdaptiveAvgPool2d((4, 4)),\n",
        "                nn.Conv2d(96, 48, 1), nn.ReLU(),\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(48 * 4 * 4, 256), nn.ReLU(), nn.Dropout(0.5),\n",
        "                nn.Linear(256, num_classes)\n",
        "            )\n",
        "\n",
        "        # ── Final classifier ──\n",
        "        self.final_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)          # → [B,32,24,24]\n",
        "        x1 = self.inc1(x)         # → [B,64,24,24]\n",
        "        x2 = self.inc2(x1)        # → [B,96,24,24]\n",
        "\n",
        "        # compute aux but ignore its output\n",
        "        if self.training and self.aux_on:\n",
        "            _ = self.aux(x2)\n",
        "\n",
        "        x3 = F.max_pool2d(x2, 2, 2)  # → [B,96,12,12]\n",
        "        x3 = self.inc3(x3)           # → [B,128,12,12]\n",
        "\n",
        "        x4 = self.final_pool(x3)     # → [B,128,1,1]\n",
        "        main_out = self.classifier(x4)\n",
        "        return main_out"
      ],
      "metadata": {
        "id": "2ydG-CJ4SsQ_"
      },
      "id": "2ydG-CJ4SsQ_",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## densenet"
      ],
      "metadata": {
        "id": "IH2tbOH_Hd8Z"
      },
      "id": "IH2tbOH_Hd8Z"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DenseLayer(nn.Module):\n",
        "    def __init__(self, in_channels, growth_rate):\n",
        "        super().__init__()\n",
        "        self.bn = nn.BatchNorm2d(in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv = nn.Conv2d(in_channels, growth_rate, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(self.relu(self.bn(x)))\n",
        "        return torch.cat([x, out], dim=1)\n",
        "\n",
        "class DenseBlock(nn.Module):\n",
        "    def __init__(self, in_channels, growth_rate, num_layers):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        for _ in range(num_layers):\n",
        "            layers.append(DenseLayer(in_channels, growth_rate))\n",
        "            in_channels += growth_rate\n",
        "        self.block = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class TransitionLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.bn = nn.BatchNorm2d(in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(self.relu(self.bn(x)))\n",
        "        return self.pool(x)\n",
        "\n",
        "class MiniDenseNet(nn.Module):\n",
        "    def __init__(self, growth_rate=12, num_classes=7):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 2 * growth_rate, kernel_size=3, padding=1, bias=False)\n",
        "        num_channels = 2 * growth_rate\n",
        "\n",
        "        self.block1 = DenseBlock(num_channels, growth_rate, num_layers=4)\n",
        "        num_channels += 4 * growth_rate\n",
        "        self.trans1 = TransitionLayer(num_channels, num_channels // 2)\n",
        "        num_channels = num_channels // 2\n",
        "\n",
        "        self.block2 = DenseBlock(num_channels, growth_rate, num_layers=4)\n",
        "        num_channels += 4 * growth_rate\n",
        "        self.trans2 = TransitionLayer(num_channels, num_channels // 2)\n",
        "        num_channels = num_channels // 2\n",
        "\n",
        "        self.bn = nn.BatchNorm2d(num_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(num_channels, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.trans1(self.block1(x))\n",
        "        x = self.trans2(self.block2(x))\n",
        "        x = self.relu(self.bn(x))\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return self.fc(x)\n"
      ],
      "metadata": {
        "id": "s_2N0muZHftN"
      },
      "id": "s_2N0muZHftN",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# geting everything ready"
      ],
      "metadata": {
        "id": "zaVbntQmXODJ"
      },
      "id": "zaVbntQmXODJ"
    },
    {
      "cell_type": "code",
      "source": [
        "def make(config):\n",
        "    # Make the data\n",
        "    train_dataset = get_data(train=True)\n",
        "    test_dataset = get_data(train=False)\n",
        "    train_loader = make_loader(train_dataset, batch_size=config.batch_size)\n",
        "    test_loader = make_loader(test_dataset, batch_size=config.batch_size)\n",
        "\n",
        "    # Make the model\n",
        "    model = MiniDenseNet().to(device)\n",
        "\n",
        "    # Make the loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "    return model, train_loader, test_loader, criterion, optimizer"
      ],
      "metadata": {
        "id": "4GOnNEKyT1v2"
      },
      "id": "4GOnNEKyT1v2",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_log(loss, example_ct, epoch):\n",
        "    # Where the magic happens\n",
        "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
        "    print(f\"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}\")"
      ],
      "metadata": {
        "id": "Jwbd9gvXUp4R"
      },
      "id": "Jwbd9gvXUp4R",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## early stop training"
      ],
      "metadata": {
        "id": "6Vih9mc96ns6"
      },
      "id": "6Vih9mc96ns6"
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, min_delta=0.0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best_loss = float('inf')\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "\n",
        "def validate(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss /= total\n",
        "    val_acc = correct / total\n",
        "    return val_loss, val_acc\n",
        "\n",
        "def train(model, train_loader, val_loader, criterion, optimizer, config):\n",
        "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=15, min_delta=0.001)\n",
        "\n",
        "    example_ct = 0\n",
        "    batch_ct = 0\n",
        "    for epoch in tqdm(range(config.epochs)):\n",
        "        model.train()\n",
        "        running_correct = 0\n",
        "        running_total = 0\n",
        "\n",
        "        for _, (images, labels) in enumerate(train_loader):\n",
        "            loss, batch_correct, batch_total = train_batch(images, labels, model, optimizer, criterion)\n",
        "            example_ct += len(images)\n",
        "            batch_ct += 1\n",
        "\n",
        "            running_correct += batch_correct\n",
        "            running_total += batch_total\n",
        "\n",
        "            if ((batch_ct + 1) % 25) == 0:\n",
        "                train_log(loss, example_ct, epoch)\n",
        "                print(f\"batch number: {batch_ct + 1}\")\n",
        "\n",
        "        train_acc = running_correct / running_total\n",
        "\n",
        "        # ⏱️ Validate at the end of the epoch\n",
        "        val_loss, val_acc = validate(model, val_loader, criterion)\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_accuracy\": val_acc,\n",
        "            \"train_accuracy\": train_acc\n",
        "        })\n",
        "        print(f\"Epoch {epoch + 1}: val_loss = {val_loss:.4f}, val_acc = {val_acc:.4f}, train_acc = {train_acc:.4f}\")\n",
        "\n",
        "        # Check early stopping\n",
        "        early_stopper(val_loss)\n",
        "        if early_stopper.early_stop:\n",
        "            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
        "            break\n",
        "def train_batch(images, labels, model, optimizer, criterion):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    total = labels.size(0)\n",
        "\n",
        "    return loss, correct, total"
      ],
      "metadata": {
        "id": "2gDrRJB56ihi"
      },
      "id": "2gDrRJB56ihi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## normal training"
      ],
      "metadata": {
        "id": "Ts0xewao6rsq"
      },
      "id": "Ts0xewao6rsq"
    },
    {
      "cell_type": "code",
      "source": [
        "# def train(model, loader, criterion, optimizer, config):\n",
        "#     # Tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
        "#     wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "\n",
        "#     # Run training and track with wandb\n",
        "#     total_batches = len(loader) * config.epochs\n",
        "#     example_ct = 0  # number of examples seen\n",
        "#     batch_ct = 0\n",
        "#     for epoch in tqdm(range(config.epochs)):\n",
        "#         for _, (images, labels) in enumerate(loader):\n",
        "\n",
        "#             loss = train_batch(images, labels, model, optimizer, criterion)\n",
        "#             example_ct +=  len(images)\n",
        "#             batch_ct += 1\n",
        "\n",
        "#             # Report metrics every 25th batch\n",
        "#             if ((batch_ct + 1) % 25) == 0:\n",
        "#                 train_log(loss, example_ct, epoch)\n",
        "#                 print(f\"batch number: {batch_ct + 1}\")\n",
        "def validate(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss /= total\n",
        "    val_acc = correct / total\n",
        "    return val_loss, val_acc\n",
        "def train(model, train_loader, val_loader, criterion, optimizer, config):\n",
        "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "\n",
        "    example_ct = 0\n",
        "    batch_ct = 0\n",
        "    for epoch in tqdm(range(config.epochs)):\n",
        "        model.train()\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "        train_loss_accumulator = 0.0\n",
        "\n",
        "        for _, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            example_ct += len(images)\n",
        "            batch_ct += 1\n",
        "\n",
        "            # Calculate training accuracy\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Accumulate loss for the epoch\n",
        "            train_loss_accumulator += loss.item() * images.size(0)\n",
        "\n",
        "            # Report metrics every 25th batch\n",
        "            if ((batch_ct + 1) % 25) == 0:\n",
        "                train_log(loss, example_ct, epoch)\n",
        "                print(f\"batch number: {batch_ct + 1}\")\n",
        "\n",
        "        # Final training metrics for the epoch\n",
        "        train_loss = train_loss_accumulator / train_total\n",
        "        train_acc = train_correct / train_total\n",
        "\n",
        "        # ⏱️ Validation step\n",
        "        val_loss, val_acc = validate(model, val_loader, criterion)\n",
        "\n",
        "        # Log both train & val metrics\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_accuracy\": train_acc,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_accuracy\": val_acc\n",
        "        })\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}: \"\n",
        "              f\"train_loss = {train_loss:.4f}, train_accuracy = {train_acc:.4f}, \"\n",
        "              f\"val_loss = {val_loss:.4f}, val_accuracy = {val_acc:.4f}\")\n",
        "def train_batch(images, labels, model, optimizer, criterion):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    # Forward pass ➡\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Backward pass ⬅\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Step with optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss\n",
        "\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "\n",
        "    # Run the model on some test examples\n",
        "    with torch.no_grad():\n",
        "        correct, total = 0, 0\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        print(f\"Accuracy of the model on the {total} \" +\n",
        "              f\"test images: {correct / total:%}\")\n",
        "\n",
        "        wandb.log({\"test_accuracy\": correct / total})\n",
        "\n",
        "    # Save the model in the exchangeable ONNX format\n",
        "    torch.onnx.export(model, images, \"model.onnx\")\n",
        "    wandb.save(\"model.onnx\")"
      ],
      "metadata": {
        "id": "F3VQ1HxlUk6V"
      },
      "id": "F3VQ1HxlUk6V",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JYjjS-iHUuUG"
      },
      "id": "JYjjS-iHUuUG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_pipeline(hyperparameters):\n",
        "\n",
        "    # tell wandb to get started\n",
        "    with wandb.init(project=\"expression_dataset_better_eval\",\n",
        "                    config=hyperparameters,\n",
        "                    name = \"MiniDenseNet\"):\n",
        "      # access all HPs through wandb.config, so logging matches execution!\n",
        "      config = wandb.config\n",
        "\n",
        "      # make the model, data, and optimization problem\n",
        "      model, train_loader, test_loader, criterion, optimizer = make(config)\n",
        "      print(model)\n",
        "\n",
        "      # and use them to train the model\n",
        "      # train(model, train_loader, criterion, optimizer, config)\n",
        "\n",
        "      # # and test its final performance\n",
        "      # test(model, test_loader)\n",
        "      train(model, train_loader, test_loader, criterion, optimizer, config)\n",
        "      test(model, test_loader)  # final test; you can use actual test set here if available\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "cEsYfYCkUbYw"
      },
      "id": "cEsYfYCkUbYw",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = dict(\n",
        "    epochs=250,\n",
        "    classes=7,\n",
        "    #kernels=[32, 64, 128],\n",
        "    batch_size=256,\n",
        "    learning_rate=2e-4,\n",
        "    dataset=\"Facial Expression Recognition\",\n",
        "    architecture=\"MiniDenseNet\")"
      ],
      "metadata": {
        "id": "GoXMnqIWY9fa"
      },
      "id": "GoXMnqIWY9fa",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train!"
      ],
      "metadata": {
        "id": "MQvkFnUNxXls"
      },
      "id": "MQvkFnUNxXls"
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_pipeline(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9dbcb31bd76b4ba492bed4578126cf55",
            "8952809bfb3a416f830985857216cd78",
            "a9b5b5c9e0a849dbab684722b876dca7",
            "e0980a635bb94fafb478a0c01986a0af",
            "b666a67396a24df280b79cf505dad8b2",
            "8d31a01c2155444aae445ab268972085",
            "814310b2af5d4217b8a22016b314865a",
            "51a03096621f414ca6b18dfe271fe546",
            "a813366a06354905b7124645a53ebdb6",
            "b48fec27b0b242ffadf5c6fad6297db6",
            "3bebdd50df804db8b7c6a76f14e300f5"
          ]
        },
        "id": "MifXx_iuXfLi",
        "outputId": "9a01f6d3-ff1e-475c-efa3-8f1f14b85751"
      },
      "id": "MifXx_iuXfLi",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250528_082027-je99a24g</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_better_eval/runs/je99a24g' target=\"_blank\">MiniDenseNet</a></strong> to <a href='https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_better_eval' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_better_eval' target=\"_blank\">https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_better_eval</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_better_eval/runs/je99a24g' target=\"_blank\">https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_better_eval/runs/je99a24g</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MiniDenseNet(\n",
            "  (conv1): Conv2d(1, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (block1): DenseBlock(\n",
            "    (block): Sequential(\n",
            "      (0): DenseLayer(\n",
            "        (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (1): DenseLayer(\n",
            "        (bn): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(36, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (2): DenseLayer(\n",
            "        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (3): DenseLayer(\n",
            "        (bn): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(60, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (trans1): TransitionLayer(\n",
            "    (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv): Conv2d(72, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  )\n",
            "  (block2): DenseBlock(\n",
            "    (block): Sequential(\n",
            "      (0): DenseLayer(\n",
            "        (bn): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(36, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (1): DenseLayer(\n",
            "        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (2): DenseLayer(\n",
            "        (bn): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(60, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (3): DenseLayer(\n",
            "        (bn): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(72, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (trans2): TransitionLayer(\n",
            "    (bn): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv): Conv2d(84, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  )\n",
            "  (bn): BatchNorm2d(42, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=42, out_features=7, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9dbcb31bd76b4ba492bed4578126cf55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train_loss = 1.9344, train_accuracy = 0.1754, val_loss = 1.9370, val_accuracy = 0.1619\n",
            "Loss after 06130 examples: 1.926\n",
            "batch number: 25\n",
            "Epoch 2: train_loss = 1.8896, train_accuracy = 0.2401, val_loss = 1.8959, val_accuracy = 0.2463\n",
            "Loss after 12516 examples: 1.868\n",
            "batch number: 50\n",
            "Epoch 3: train_loss = 1.8643, train_accuracy = 0.2704, val_loss = 1.8642, val_accuracy = 0.2611\n",
            "Epoch 4: train_loss = 1.8470, train_accuracy = 0.2762, val_loss = 1.8508, val_accuracy = 0.2585\n",
            "Loss after 18888 examples: 1.813\n",
            "batch number: 75\n",
            "Epoch 5: train_loss = 1.8324, train_accuracy = 0.2819, val_loss = 1.8446, val_accuracy = 0.2620\n",
            "Loss after 25274 examples: 1.830\n",
            "batch number: 100\n",
            "Epoch 6: train_loss = 1.8188, train_accuracy = 0.2797, val_loss = 1.8286, val_accuracy = 0.2585\n",
            "Loss after 31660 examples: 1.793\n",
            "batch number: 125\n",
            "Epoch 7: train_loss = 1.8077, train_accuracy = 0.2906, val_loss = 1.8251, val_accuracy = 0.2707\n",
            "Epoch 8: train_loss = 1.7972, train_accuracy = 0.2945, val_loss = 1.8110, val_accuracy = 0.2863\n",
            "Loss after 38032 examples: 1.775\n",
            "batch number: 150\n",
            "Epoch 9: train_loss = 1.7861, train_accuracy = 0.2978, val_loss = 1.8055, val_accuracy = 0.2785\n",
            "Loss after 44418 examples: 1.795\n",
            "batch number: 175\n",
            "Epoch 10: train_loss = 1.7772, train_accuracy = 0.3032, val_loss = 1.7862, val_accuracy = 0.2985\n",
            "Epoch 11: train_loss = 1.7660, train_accuracy = 0.3084, val_loss = 1.8006, val_accuracy = 0.2489\n",
            "Loss after 50790 examples: 1.748\n",
            "batch number: 200\n",
            "Epoch 12: train_loss = 1.7537, train_accuracy = 0.3121, val_loss = 1.7809, val_accuracy = 0.2898\n",
            "Loss after 57176 examples: 1.736\n",
            "batch number: 225\n",
            "Epoch 13: train_loss = 1.7425, train_accuracy = 0.3137, val_loss = 1.7557, val_accuracy = 0.3124\n",
            "Loss after 63562 examples: 1.721\n",
            "batch number: 250\n",
            "Epoch 14: train_loss = 1.7284, train_accuracy = 0.3235, val_loss = 1.7468, val_accuracy = 0.3072\n",
            "Epoch 15: train_loss = 1.7143, train_accuracy = 0.3289, val_loss = 1.7266, val_accuracy = 0.3107\n",
            "Loss after 69934 examples: 1.642\n",
            "batch number: 275\n",
            "Epoch 16: train_loss = 1.6995, train_accuracy = 0.3348, val_loss = 1.7216, val_accuracy = 0.3151\n",
            "Loss after 76320 examples: 1.685\n",
            "batch number: 300\n",
            "Epoch 17: train_loss = 1.6857, train_accuracy = 0.3385, val_loss = 1.7750, val_accuracy = 0.2829\n",
            "Loss after 82692 examples: 1.690\n",
            "batch number: 325\n",
            "Epoch 18: train_loss = 1.6784, train_accuracy = 0.3420, val_loss = 1.7137, val_accuracy = 0.2994\n",
            "Epoch 19: train_loss = 1.6587, train_accuracy = 0.3522, val_loss = 1.6829, val_accuracy = 0.3455\n",
            "Loss after 89078 examples: 1.645\n",
            "batch number: 350\n",
            "Epoch 20: train_loss = 1.6521, train_accuracy = 0.3653, val_loss = 1.6634, val_accuracy = 0.3438\n",
            "Loss after 95464 examples: 1.629\n",
            "batch number: 375\n",
            "Epoch 21: train_loss = 1.6292, train_accuracy = 0.3663, val_loss = 1.6637, val_accuracy = 0.3299\n",
            "Epoch 22: train_loss = 1.6106, train_accuracy = 0.3746, val_loss = 1.7170, val_accuracy = 0.2933\n",
            "Loss after 101836 examples: 1.651\n",
            "batch number: 400\n",
            "Epoch 23: train_loss = 1.6040, train_accuracy = 0.3846, val_loss = 1.6270, val_accuracy = 0.3664\n",
            "Loss after 108222 examples: 1.590\n",
            "batch number: 425\n",
            "Epoch 24: train_loss = 1.5950, train_accuracy = 0.3851, val_loss = 1.6809, val_accuracy = 0.3133\n",
            "Loss after 114608 examples: 1.611\n",
            "batch number: 450\n",
            "Epoch 25: train_loss = 1.5818, train_accuracy = 0.3933, val_loss = 1.6307, val_accuracy = 0.3586\n",
            "Epoch 26: train_loss = 1.5664, train_accuracy = 0.3981, val_loss = 1.7193, val_accuracy = 0.3107\n",
            "Loss after 120980 examples: 1.567\n",
            "batch number: 475\n",
            "Epoch 27: train_loss = 1.5541, train_accuracy = 0.4031, val_loss = 1.6451, val_accuracy = 0.3638\n",
            "Loss after 127366 examples: 1.597\n",
            "batch number: 500\n",
            "Epoch 28: train_loss = 1.5316, train_accuracy = 0.4205, val_loss = 1.6499, val_accuracy = 0.3177\n",
            "Epoch 29: train_loss = 1.5308, train_accuracy = 0.4264, val_loss = 1.5792, val_accuracy = 0.3699\n",
            "Loss after 133738 examples: 1.566\n",
            "batch number: 525\n",
            "Epoch 30: train_loss = 1.5253, train_accuracy = 0.4205, val_loss = 1.6286, val_accuracy = 0.3368\n",
            "Loss after 140124 examples: 1.510\n",
            "batch number: 550\n",
            "Epoch 31: train_loss = 1.5027, train_accuracy = 0.4286, val_loss = 1.5891, val_accuracy = 0.3681\n",
            "Loss after 146510 examples: 1.523\n",
            "batch number: 575\n",
            "Epoch 32: train_loss = 1.4961, train_accuracy = 0.4340, val_loss = 1.6567, val_accuracy = 0.3290\n",
            "Epoch 33: train_loss = 1.4935, train_accuracy = 0.4373, val_loss = 1.8058, val_accuracy = 0.2959\n",
            "Loss after 152882 examples: 1.531\n",
            "batch number: 600\n",
            "Epoch 34: train_loss = 1.4782, train_accuracy = 0.4391, val_loss = 1.6694, val_accuracy = 0.3438\n",
            "Loss after 159268 examples: 1.497\n",
            "batch number: 625\n",
            "Epoch 35: train_loss = 1.4604, train_accuracy = 0.4512, val_loss = 1.6171, val_accuracy = 0.3499\n",
            "Epoch 36: train_loss = 1.4477, train_accuracy = 0.4619, val_loss = 1.6379, val_accuracy = 0.3586\n",
            "Loss after 165640 examples: 1.386\n",
            "batch number: 650\n",
            "Epoch 37: train_loss = 1.4445, train_accuracy = 0.4560, val_loss = 1.5482, val_accuracy = 0.3873\n",
            "Loss after 172026 examples: 1.468\n",
            "batch number: 675\n",
            "Epoch 38: train_loss = 1.4272, train_accuracy = 0.4626, val_loss = 1.9039, val_accuracy = 0.2776\n",
            "Loss after 178412 examples: 1.434\n",
            "batch number: 700\n",
            "Epoch 39: train_loss = 1.4254, train_accuracy = 0.4669, val_loss = 1.5609, val_accuracy = 0.3908\n",
            "Epoch 40: train_loss = 1.4104, train_accuracy = 0.4763, val_loss = 1.5615, val_accuracy = 0.3899\n",
            "Loss after 184784 examples: 1.412\n",
            "batch number: 725\n",
            "Epoch 41: train_loss = 1.3967, train_accuracy = 0.4830, val_loss = 1.7843, val_accuracy = 0.3020\n",
            "Loss after 191170 examples: 1.346\n",
            "batch number: 750\n",
            "Epoch 42: train_loss = 1.3917, train_accuracy = 0.4763, val_loss = 1.5462, val_accuracy = 0.3734\n",
            "Loss after 197542 examples: 1.424\n",
            "batch number: 775\n",
            "Epoch 43: train_loss = 1.3787, train_accuracy = 0.4824, val_loss = 1.5669, val_accuracy = 0.3995\n",
            "Epoch 44: train_loss = 1.3762, train_accuracy = 0.4739, val_loss = 1.5786, val_accuracy = 0.3699\n",
            "Loss after 203928 examples: 1.439\n",
            "batch number: 800\n",
            "Epoch 45: train_loss = 1.3596, train_accuracy = 0.4928, val_loss = 1.5459, val_accuracy = 0.3986\n",
            "Loss after 210314 examples: 1.318\n",
            "batch number: 825\n",
            "Epoch 46: train_loss = 1.3622, train_accuracy = 0.4915, val_loss = 2.1276, val_accuracy = 0.2211\n",
            "Epoch 47: train_loss = 1.3550, train_accuracy = 0.4878, val_loss = 1.5061, val_accuracy = 0.4099\n",
            "Loss after 216686 examples: 1.378\n",
            "batch number: 850\n",
            "Epoch 48: train_loss = 1.3369, train_accuracy = 0.5094, val_loss = 1.4970, val_accuracy = 0.4221\n",
            "Loss after 223072 examples: 1.322\n",
            "batch number: 875\n",
            "Epoch 49: train_loss = 1.3297, train_accuracy = 0.5070, val_loss = 1.5584, val_accuracy = 0.3943\n",
            "Loss after 229458 examples: 1.298\n",
            "batch number: 900\n",
            "Epoch 50: train_loss = 1.3187, train_accuracy = 0.5089, val_loss = 1.4872, val_accuracy = 0.4047\n",
            "Epoch 51: train_loss = 1.3194, train_accuracy = 0.5078, val_loss = 2.2636, val_accuracy = 0.3133\n",
            "Loss after 235830 examples: 1.352\n",
            "batch number: 925\n",
            "Epoch 52: train_loss = 1.3084, train_accuracy = 0.5102, val_loss = 1.5464, val_accuracy = 0.3829\n",
            "Loss after 242216 examples: 1.346\n",
            "batch number: 950\n",
            "Epoch 53: train_loss = 1.2869, train_accuracy = 0.5205, val_loss = 1.5768, val_accuracy = 0.3908\n",
            "Epoch 54: train_loss = 1.2691, train_accuracy = 0.5346, val_loss = 1.5715, val_accuracy = 0.3995\n",
            "Loss after 248588 examples: 1.293\n",
            "batch number: 975\n",
            "Epoch 55: train_loss = 1.2609, train_accuracy = 0.5353, val_loss = 1.5135, val_accuracy = 0.4247\n",
            "Loss after 254974 examples: 1.307\n",
            "batch number: 1000\n",
            "Epoch 56: train_loss = 1.2620, train_accuracy = 0.5403, val_loss = 1.6839, val_accuracy = 0.3708\n",
            "Loss after 261360 examples: 1.280\n",
            "batch number: 1025\n",
            "Epoch 57: train_loss = 1.2591, train_accuracy = 0.5344, val_loss = 1.5332, val_accuracy = 0.4003\n",
            "Epoch 58: train_loss = 1.2437, train_accuracy = 0.5446, val_loss = 1.7497, val_accuracy = 0.3325\n",
            "Loss after 267732 examples: 1.243\n",
            "batch number: 1050\n",
            "Epoch 59: train_loss = 1.2405, train_accuracy = 0.5401, val_loss = 1.4969, val_accuracy = 0.4299\n",
            "Loss after 274118 examples: 1.204\n",
            "batch number: 1075\n",
            "Epoch 60: train_loss = 1.2216, train_accuracy = 0.5531, val_loss = 1.5682, val_accuracy = 0.3977\n",
            "Epoch 61: train_loss = 1.2231, train_accuracy = 0.5542, val_loss = 1.6321, val_accuracy = 0.3673\n",
            "Loss after 280490 examples: 1.264\n",
            "batch number: 1100\n",
            "Epoch 62: train_loss = 1.2232, train_accuracy = 0.5475, val_loss = 1.5722, val_accuracy = 0.3986\n",
            "Loss after 286876 examples: 1.144\n",
            "batch number: 1125\n",
            "Epoch 63: train_loss = 1.2053, train_accuracy = 0.5544, val_loss = 1.5431, val_accuracy = 0.4073\n",
            "Loss after 293262 examples: 1.212\n",
            "batch number: 1150\n",
            "Epoch 64: train_loss = 1.1984, train_accuracy = 0.5640, val_loss = 1.5186, val_accuracy = 0.4082\n",
            "Epoch 65: train_loss = 1.1817, train_accuracy = 0.5649, val_loss = 1.5824, val_accuracy = 0.3916\n",
            "Loss after 299634 examples: 1.157\n",
            "batch number: 1175\n",
            "Epoch 66: train_loss = 1.1868, train_accuracy = 0.5653, val_loss = 1.4957, val_accuracy = 0.4047\n",
            "Loss after 306020 examples: 1.214\n",
            "batch number: 1200\n",
            "Epoch 67: train_loss = 1.1673, train_accuracy = 0.5723, val_loss = 1.5321, val_accuracy = 0.4238\n",
            "Loss after 312392 examples: 1.223\n",
            "batch number: 1225\n",
            "Epoch 68: train_loss = 1.1742, train_accuracy = 0.5694, val_loss = 1.5106, val_accuracy = 0.4439\n",
            "Epoch 69: train_loss = 1.1411, train_accuracy = 0.5877, val_loss = 1.5534, val_accuracy = 0.4247\n",
            "Loss after 318778 examples: 1.124\n",
            "batch number: 1250\n",
            "Epoch 70: train_loss = 1.1481, train_accuracy = 0.5845, val_loss = 1.5040, val_accuracy = 0.4360\n",
            "Loss after 325164 examples: 1.167\n",
            "batch number: 1275\n",
            "Epoch 71: train_loss = 1.1687, train_accuracy = 0.5657, val_loss = 1.6042, val_accuracy = 0.3899\n",
            "Epoch 72: train_loss = 1.1414, train_accuracy = 0.5797, val_loss = 1.4588, val_accuracy = 0.4482\n",
            "Loss after 331536 examples: 1.098\n",
            "batch number: 1300\n",
            "Epoch 73: train_loss = 1.1229, train_accuracy = 0.5875, val_loss = 1.5813, val_accuracy = 0.4108\n",
            "Loss after 337922 examples: 1.208\n",
            "batch number: 1325\n",
            "Epoch 74: train_loss = 1.1306, train_accuracy = 0.5953, val_loss = 1.8184, val_accuracy = 0.3612\n",
            "Loss after 344308 examples: 1.090\n",
            "batch number: 1350\n",
            "Epoch 75: train_loss = 1.1159, train_accuracy = 0.5866, val_loss = 1.6075, val_accuracy = 0.3969\n",
            "Epoch 76: train_loss = 1.1009, train_accuracy = 0.5975, val_loss = 1.5406, val_accuracy = 0.4343\n",
            "Loss after 350680 examples: 1.096\n",
            "batch number: 1375\n",
            "Epoch 77: train_loss = 1.0875, train_accuracy = 0.6080, val_loss = 1.4933, val_accuracy = 0.4265\n",
            "Loss after 357066 examples: 1.038\n",
            "batch number: 1400\n",
            "Epoch 78: train_loss = 1.0797, train_accuracy = 0.6067, val_loss = 1.7712, val_accuracy = 0.3821\n",
            "Epoch 79: train_loss = 1.0823, train_accuracy = 0.6001, val_loss = 1.7234, val_accuracy = 0.3507\n",
            "Loss after 363438 examples: 1.115\n",
            "batch number: 1425\n",
            "Epoch 80: train_loss = 1.0881, train_accuracy = 0.6080, val_loss = 1.5419, val_accuracy = 0.4169\n",
            "Loss after 369824 examples: 1.111\n",
            "batch number: 1450\n",
            "Epoch 81: train_loss = 1.0721, train_accuracy = 0.6154, val_loss = 1.7181, val_accuracy = 0.3760\n",
            "Loss after 376210 examples: 0.991\n",
            "batch number: 1475\n",
            "Epoch 82: train_loss = 1.0507, train_accuracy = 0.6256, val_loss = 1.6870, val_accuracy = 0.3681\n",
            "Epoch 83: train_loss = 1.0415, train_accuracy = 0.6254, val_loss = 1.9512, val_accuracy = 0.3812\n",
            "Loss after 382582 examples: 0.988\n",
            "batch number: 1500\n",
            "Epoch 84: train_loss = 1.0450, train_accuracy = 0.6284, val_loss = 1.6614, val_accuracy = 0.3786\n",
            "Loss after 388968 examples: 1.000\n",
            "batch number: 1525\n",
            "Epoch 85: train_loss = 1.0197, train_accuracy = 0.6408, val_loss = 1.5041, val_accuracy = 0.4334\n",
            "Epoch 86: train_loss = 1.0096, train_accuracy = 0.6448, val_loss = 1.5260, val_accuracy = 0.4343\n",
            "Loss after 395340 examples: 1.068\n",
            "batch number: 1550\n",
            "Epoch 87: train_loss = 1.0168, train_accuracy = 0.6321, val_loss = 1.5784, val_accuracy = 0.4134\n",
            "Loss after 401726 examples: 1.019\n",
            "batch number: 1575\n",
            "Epoch 88: train_loss = 1.0235, train_accuracy = 0.6347, val_loss = 1.6744, val_accuracy = 0.3829\n",
            "Loss after 408112 examples: 0.975\n",
            "batch number: 1600\n",
            "Epoch 89: train_loss = 1.0118, train_accuracy = 0.6378, val_loss = 2.7661, val_accuracy = 0.2472\n",
            "Epoch 90: train_loss = 1.0205, train_accuracy = 0.6326, val_loss = 1.6965, val_accuracy = 0.3890\n",
            "Loss after 414484 examples: 0.961\n",
            "batch number: 1625\n",
            "Epoch 91: train_loss = 0.9935, train_accuracy = 0.6445, val_loss = 1.5410, val_accuracy = 0.4099\n",
            "Loss after 420870 examples: 0.927\n",
            "batch number: 1650\n",
            "Epoch 92: train_loss = 0.9885, train_accuracy = 0.6406, val_loss = 1.5112, val_accuracy = 0.4378\n",
            "Loss after 427242 examples: 1.100\n",
            "batch number: 1675\n",
            "Epoch 93: train_loss = 0.9856, train_accuracy = 0.6456, val_loss = 1.8058, val_accuracy = 0.3777\n",
            "Epoch 94: train_loss = 0.9864, train_accuracy = 0.6502, val_loss = 1.6293, val_accuracy = 0.3995\n",
            "Loss after 433628 examples: 0.908\n",
            "batch number: 1700\n",
            "Epoch 95: train_loss = 0.9576, train_accuracy = 0.6657, val_loss = 1.5875, val_accuracy = 0.4360\n",
            "Loss after 440014 examples: 1.038\n",
            "batch number: 1725\n",
            "Epoch 96: train_loss = 0.9479, train_accuracy = 0.6674, val_loss = 1.9065, val_accuracy = 0.3621\n",
            "Epoch 97: train_loss = 0.9438, train_accuracy = 0.6761, val_loss = 1.5294, val_accuracy = 0.4482\n",
            "Loss after 446386 examples: 0.944\n",
            "batch number: 1750\n",
            "Epoch 98: train_loss = 0.9378, train_accuracy = 0.6761, val_loss = 1.6790, val_accuracy = 0.3916\n",
            "Loss after 452772 examples: 0.962\n",
            "batch number: 1775\n",
            "Epoch 99: train_loss = 0.9284, train_accuracy = 0.6798, val_loss = 1.5359, val_accuracy = 0.4256\n",
            "Loss after 459158 examples: 0.901\n",
            "batch number: 1800\n",
            "Epoch 100: train_loss = 0.9087, train_accuracy = 0.6879, val_loss = 1.6210, val_accuracy = 0.4160\n",
            "Epoch 101: train_loss = 0.9052, train_accuracy = 0.6907, val_loss = 1.5688, val_accuracy = 0.4230\n",
            "Loss after 465530 examples: 0.824\n",
            "batch number: 1825\n",
            "Epoch 102: train_loss = 0.9004, train_accuracy = 0.6900, val_loss = 1.5240, val_accuracy = 0.4465\n",
            "Loss after 471916 examples: 0.981\n",
            "batch number: 1850\n",
            "Epoch 103: train_loss = 0.9065, train_accuracy = 0.6894, val_loss = 1.6636, val_accuracy = 0.3856\n",
            "Epoch 104: train_loss = 0.9133, train_accuracy = 0.6855, val_loss = 1.6206, val_accuracy = 0.4299\n",
            "Loss after 478288 examples: 0.919\n",
            "batch number: 1875\n",
            "Epoch 105: train_loss = 0.9010, train_accuracy = 0.6942, val_loss = 1.6890, val_accuracy = 0.4125\n",
            "Loss after 484674 examples: 0.901\n",
            "batch number: 1900\n",
            "Epoch 106: train_loss = 0.8999, train_accuracy = 0.6922, val_loss = 2.4229, val_accuracy = 0.3316\n",
            "Loss after 491060 examples: 0.832\n",
            "batch number: 1925\n",
            "Epoch 107: train_loss = 0.8757, train_accuracy = 0.7044, val_loss = 1.4890, val_accuracy = 0.4517\n",
            "Epoch 108: train_loss = 0.8763, train_accuracy = 0.7044, val_loss = 1.6145, val_accuracy = 0.4125\n",
            "Loss after 497432 examples: 0.803\n",
            "batch number: 1950\n",
            "Epoch 109: train_loss = 0.8689, train_accuracy = 0.7122, val_loss = 1.6884, val_accuracy = 0.3768\n",
            "Loss after 503818 examples: 0.864\n",
            "batch number: 1975\n",
            "Epoch 110: train_loss = 0.8587, train_accuracy = 0.7116, val_loss = 1.8960, val_accuracy = 0.3664\n",
            "Epoch 111: train_loss = 0.8540, train_accuracy = 0.7053, val_loss = 1.7111, val_accuracy = 0.4125\n",
            "Loss after 510190 examples: 0.951\n",
            "batch number: 2000\n",
            "Epoch 112: train_loss = 0.8687, train_accuracy = 0.7009, val_loss = 1.6070, val_accuracy = 0.4186\n",
            "Loss after 516576 examples: 0.801\n",
            "batch number: 2025\n",
            "Epoch 113: train_loss = 0.8498, train_accuracy = 0.7129, val_loss = 1.7403, val_accuracy = 0.4021\n",
            "Loss after 522962 examples: 0.853\n",
            "batch number: 2050\n",
            "Epoch 114: train_loss = 0.8447, train_accuracy = 0.7190, val_loss = 1.7751, val_accuracy = 0.4169\n",
            "Epoch 115: train_loss = 0.8339, train_accuracy = 0.7209, val_loss = 1.7058, val_accuracy = 0.4038\n",
            "Loss after 529334 examples: 0.828\n",
            "batch number: 2075\n",
            "Epoch 116: train_loss = 0.8237, train_accuracy = 0.7255, val_loss = 1.5327, val_accuracy = 0.4395\n",
            "Loss after 535720 examples: 0.871\n",
            "batch number: 2100\n",
            "Epoch 117: train_loss = 0.8148, train_accuracy = 0.7283, val_loss = 1.8176, val_accuracy = 0.3960\n",
            "Loss after 542092 examples: 0.787\n",
            "batch number: 2125\n",
            "Epoch 118: train_loss = 0.7954, train_accuracy = 0.7421, val_loss = 1.6360, val_accuracy = 0.4178\n",
            "Epoch 119: train_loss = 0.7872, train_accuracy = 0.7486, val_loss = 1.6646, val_accuracy = 0.4447\n",
            "Loss after 548478 examples: 0.861\n",
            "batch number: 2150\n",
            "Epoch 120: train_loss = 0.7838, train_accuracy = 0.7484, val_loss = 1.9480, val_accuracy = 0.3969\n",
            "Loss after 554864 examples: 0.867\n",
            "batch number: 2175\n",
            "Epoch 121: train_loss = 0.7956, train_accuracy = 0.7381, val_loss = 1.7611, val_accuracy = 0.4178\n",
            "Epoch 122: train_loss = 0.7881, train_accuracy = 0.7344, val_loss = 1.7055, val_accuracy = 0.4056\n",
            "Loss after 561236 examples: 0.785\n",
            "batch number: 2200\n",
            "Epoch 123: train_loss = 0.7671, train_accuracy = 0.7588, val_loss = 1.5757, val_accuracy = 0.4299\n",
            "Loss after 567622 examples: 0.731\n",
            "batch number: 2225\n",
            "Epoch 124: train_loss = 0.7577, train_accuracy = 0.7584, val_loss = 2.4417, val_accuracy = 0.2942\n",
            "Loss after 574008 examples: 0.808\n",
            "batch number: 2250\n",
            "Epoch 125: train_loss = 0.7466, train_accuracy = 0.7638, val_loss = 1.6151, val_accuracy = 0.4413\n",
            "Epoch 126: train_loss = 0.7462, train_accuracy = 0.7640, val_loss = 1.8117, val_accuracy = 0.4064\n",
            "Loss after 580380 examples: 0.648\n",
            "batch number: 2275\n",
            "Epoch 127: train_loss = 0.7488, train_accuracy = 0.7701, val_loss = 1.7191, val_accuracy = 0.4038\n",
            "Loss after 586766 examples: 0.772\n",
            "batch number: 2300\n",
            "Epoch 128: train_loss = 0.7384, train_accuracy = 0.7688, val_loss = 1.7443, val_accuracy = 0.4169\n",
            "Epoch 129: train_loss = 0.7351, train_accuracy = 0.7695, val_loss = 1.6778, val_accuracy = 0.4343\n",
            "Loss after 593138 examples: 0.689\n",
            "batch number: 2325\n",
            "Epoch 130: train_loss = 0.7265, train_accuracy = 0.7721, val_loss = 1.6108, val_accuracy = 0.4195\n",
            "Loss after 599524 examples: 0.697\n",
            "batch number: 2350\n",
            "Epoch 131: train_loss = 0.7057, train_accuracy = 0.7812, val_loss = 1.6651, val_accuracy = 0.4378\n",
            "Loss after 605910 examples: 0.684\n",
            "batch number: 2375\n",
            "Epoch 132: train_loss = 0.7116, train_accuracy = 0.7808, val_loss = 2.5439, val_accuracy = 0.3185\n",
            "Epoch 133: train_loss = 0.7069, train_accuracy = 0.7795, val_loss = 1.6270, val_accuracy = 0.4386\n",
            "Loss after 612282 examples: 0.670\n",
            "batch number: 2400\n",
            "Epoch 134: train_loss = 0.7000, train_accuracy = 0.7849, val_loss = 1.8053, val_accuracy = 0.4125\n",
            "Loss after 618668 examples: 0.791\n",
            "batch number: 2425\n",
            "Epoch 135: train_loss = 0.6951, train_accuracy = 0.7884, val_loss = 1.7895, val_accuracy = 0.4204\n",
            "Epoch 136: train_loss = 0.6877, train_accuracy = 0.7934, val_loss = 2.0181, val_accuracy = 0.3925\n",
            "Loss after 625040 examples: 0.659\n",
            "batch number: 2450\n",
            "Epoch 137: train_loss = 0.6783, train_accuracy = 0.7982, val_loss = 1.6356, val_accuracy = 0.4308\n",
            "Loss after 631426 examples: 0.659\n",
            "batch number: 2475\n",
            "Epoch 138: train_loss = 0.6889, train_accuracy = 0.7923, val_loss = 1.8974, val_accuracy = 0.3986\n",
            "Loss after 637812 examples: 0.629\n",
            "batch number: 2500\n",
            "Epoch 139: train_loss = 0.6787, train_accuracy = 0.7958, val_loss = 1.7193, val_accuracy = 0.4178\n",
            "Epoch 140: train_loss = 0.6489, train_accuracy = 0.8143, val_loss = 1.6822, val_accuracy = 0.4299\n",
            "Loss after 644184 examples: 0.649\n",
            "batch number: 2525\n",
            "Epoch 141: train_loss = 0.6537, train_accuracy = 0.8030, val_loss = 1.8532, val_accuracy = 0.3847\n",
            "Loss after 650570 examples: 0.703\n",
            "batch number: 2550\n",
            "Epoch 142: train_loss = 0.6346, train_accuracy = 0.8130, val_loss = 1.6306, val_accuracy = 0.4386\n",
            "Loss after 656942 examples: 0.797\n",
            "batch number: 2575\n",
            "Epoch 143: train_loss = 0.6366, train_accuracy = 0.8156, val_loss = 1.8690, val_accuracy = 0.3403\n",
            "Epoch 144: train_loss = 0.6391, train_accuracy = 0.8098, val_loss = 1.6172, val_accuracy = 0.4456\n",
            "Loss after 663328 examples: 0.615\n",
            "batch number: 2600\n",
            "Epoch 145: train_loss = 0.6330, train_accuracy = 0.8130, val_loss = 1.6566, val_accuracy = 0.4291\n",
            "Loss after 669714 examples: 0.644\n",
            "batch number: 2625\n",
            "Epoch 146: train_loss = 0.6353, train_accuracy = 0.8041, val_loss = 1.9042, val_accuracy = 0.4169\n",
            "Epoch 147: train_loss = 0.6447, train_accuracy = 0.8043, val_loss = 1.6657, val_accuracy = 0.4343\n",
            "Loss after 676086 examples: 0.598\n",
            "batch number: 2650\n",
            "Epoch 148: train_loss = 0.6162, train_accuracy = 0.8232, val_loss = 1.7803, val_accuracy = 0.3916\n",
            "Loss after 682472 examples: 0.586\n",
            "batch number: 2675\n",
            "Epoch 149: train_loss = 0.6119, train_accuracy = 0.8252, val_loss = 1.6823, val_accuracy = 0.4273\n",
            "Loss after 688858 examples: 0.565\n",
            "batch number: 2700\n",
            "Epoch 150: train_loss = 0.6001, train_accuracy = 0.8298, val_loss = 1.8655, val_accuracy = 0.3977\n",
            "Epoch 151: train_loss = 0.5854, train_accuracy = 0.8424, val_loss = 1.7602, val_accuracy = 0.4369\n",
            "Loss after 695230 examples: 0.622\n",
            "batch number: 2725\n",
            "Epoch 152: train_loss = 0.5922, train_accuracy = 0.8337, val_loss = 2.0011, val_accuracy = 0.3638\n",
            "Loss after 701616 examples: 0.607\n",
            "batch number: 2750\n",
            "Epoch 153: train_loss = 0.5746, train_accuracy = 0.8383, val_loss = 1.7839, val_accuracy = 0.4169\n",
            "Epoch 154: train_loss = 0.5540, train_accuracy = 0.8561, val_loss = 2.0098, val_accuracy = 0.3525\n",
            "Loss after 707988 examples: 0.583\n",
            "batch number: 2775\n",
            "Epoch 155: train_loss = 0.5521, train_accuracy = 0.8529, val_loss = 1.7993, val_accuracy = 0.4108\n",
            "Loss after 714374 examples: 0.543\n",
            "batch number: 2800\n",
            "Epoch 156: train_loss = 0.5530, train_accuracy = 0.8570, val_loss = 1.7547, val_accuracy = 0.4473\n",
            "Loss after 720760 examples: 0.529\n",
            "batch number: 2825\n",
            "Epoch 157: train_loss = 0.5573, train_accuracy = 0.8535, val_loss = 2.3485, val_accuracy = 0.4021\n",
            "Epoch 158: train_loss = 0.5451, train_accuracy = 0.8583, val_loss = 2.4860, val_accuracy = 0.3507\n",
            "Loss after 727132 examples: 0.558\n",
            "batch number: 2850\n",
            "Epoch 159: train_loss = 0.5473, train_accuracy = 0.8570, val_loss = 1.7665, val_accuracy = 0.4247\n",
            "Loss after 733518 examples: 0.542\n",
            "batch number: 2875\n",
            "Epoch 160: train_loss = 0.5286, train_accuracy = 0.8620, val_loss = 2.4133, val_accuracy = 0.3359\n",
            "Epoch 161: train_loss = 0.5315, train_accuracy = 0.8642, val_loss = 2.1469, val_accuracy = 0.3829\n",
            "Loss after 739890 examples: 0.462\n",
            "batch number: 2900\n",
            "Epoch 162: train_loss = 0.5382, train_accuracy = 0.8607, val_loss = 2.0265, val_accuracy = 0.4082\n",
            "Loss after 746276 examples: 0.545\n",
            "batch number: 2925\n",
            "Epoch 163: train_loss = 0.5326, train_accuracy = 0.8611, val_loss = 1.7840, val_accuracy = 0.4151\n",
            "Loss after 752662 examples: 0.490\n",
            "batch number: 2950\n",
            "Epoch 164: train_loss = 0.5069, train_accuracy = 0.8781, val_loss = 1.8007, val_accuracy = 0.4212\n",
            "Epoch 165: train_loss = 0.5033, train_accuracy = 0.8727, val_loss = 1.7743, val_accuracy = 0.4465\n",
            "Loss after 759034 examples: 0.497\n",
            "batch number: 2975\n",
            "Epoch 166: train_loss = 0.5037, train_accuracy = 0.8783, val_loss = 1.7784, val_accuracy = 0.4091\n",
            "Loss after 765420 examples: 0.504\n",
            "batch number: 3000\n",
            "Epoch 167: train_loss = 0.4899, train_accuracy = 0.8809, val_loss = 1.9512, val_accuracy = 0.4308\n",
            "Loss after 771792 examples: 0.544\n",
            "batch number: 3025\n",
            "Epoch 168: train_loss = 0.5003, train_accuracy = 0.8716, val_loss = 2.1162, val_accuracy = 0.3647\n",
            "Epoch 169: train_loss = 0.5030, train_accuracy = 0.8690, val_loss = 1.8696, val_accuracy = 0.3969\n",
            "Loss after 778178 examples: 0.497\n",
            "batch number: 3050\n",
            "Epoch 170: train_loss = 0.4930, train_accuracy = 0.8827, val_loss = 2.1127, val_accuracy = 0.3690\n",
            "Loss after 784564 examples: 0.537\n",
            "batch number: 3075\n",
            "Epoch 171: train_loss = 0.4689, train_accuracy = 0.8879, val_loss = 1.8765, val_accuracy = 0.4326\n",
            "Epoch 172: train_loss = 0.4824, train_accuracy = 0.8809, val_loss = 1.8294, val_accuracy = 0.4212\n",
            "Loss after 790936 examples: 0.439\n",
            "batch number: 3100\n",
            "Epoch 173: train_loss = 0.4678, train_accuracy = 0.8909, val_loss = 1.8458, val_accuracy = 0.4204\n",
            "Loss after 797322 examples: 0.427\n",
            "batch number: 3125\n",
            "Epoch 174: train_loss = 0.4547, train_accuracy = 0.8992, val_loss = 1.8720, val_accuracy = 0.4308\n",
            "Loss after 803708 examples: 0.475\n",
            "batch number: 3150\n",
            "Epoch 175: train_loss = 0.4648, train_accuracy = 0.8901, val_loss = 1.8436, val_accuracy = 0.4169\n",
            "Epoch 176: train_loss = 0.4420, train_accuracy = 0.9018, val_loss = 1.8716, val_accuracy = 0.4230\n",
            "Loss after 810080 examples: 0.413\n",
            "batch number: 3175\n",
            "Epoch 177: train_loss = 0.4195, train_accuracy = 0.9155, val_loss = 1.9743, val_accuracy = 0.4221\n",
            "Loss after 816466 examples: 0.513\n",
            "batch number: 3200\n",
            "Epoch 178: train_loss = 0.4349, train_accuracy = 0.8964, val_loss = 1.8716, val_accuracy = 0.4134\n",
            "Epoch 179: train_loss = 0.4502, train_accuracy = 0.8960, val_loss = 2.0810, val_accuracy = 0.3908\n",
            "Loss after 822838 examples: 0.430\n",
            "batch number: 3225\n",
            "Epoch 180: train_loss = 0.4521, train_accuracy = 0.8901, val_loss = 2.2573, val_accuracy = 0.4143\n",
            "Loss after 829224 examples: 0.414\n",
            "batch number: 3250\n",
            "Epoch 181: train_loss = 0.4301, train_accuracy = 0.9025, val_loss = 1.9992, val_accuracy = 0.3873\n",
            "Loss after 835610 examples: 0.459\n",
            "batch number: 3275\n",
            "Epoch 182: train_loss = 0.4153, train_accuracy = 0.9114, val_loss = 1.9524, val_accuracy = 0.4047\n",
            "Epoch 183: train_loss = 0.4131, train_accuracy = 0.9129, val_loss = 2.2220, val_accuracy = 0.3838\n",
            "Loss after 841982 examples: 0.430\n",
            "batch number: 3300\n",
            "Epoch 184: train_loss = 0.4224, train_accuracy = 0.9057, val_loss = 2.8227, val_accuracy = 0.3290\n",
            "Loss after 848368 examples: 0.397\n",
            "batch number: 3325\n",
            "Epoch 185: train_loss = 0.4249, train_accuracy = 0.9023, val_loss = 1.8930, val_accuracy = 0.4178\n",
            "Epoch 186: train_loss = 0.3903, train_accuracy = 0.9188, val_loss = 1.8503, val_accuracy = 0.4256\n",
            "Loss after 854740 examples: 0.353\n",
            "batch number: 3350\n",
            "Epoch 187: train_loss = 0.3834, train_accuracy = 0.9247, val_loss = 2.0945, val_accuracy = 0.3951\n",
            "Loss after 861126 examples: 0.423\n",
            "batch number: 3375\n",
            "Epoch 188: train_loss = 0.3825, train_accuracy = 0.9245, val_loss = 1.9041, val_accuracy = 0.4108\n",
            "Loss after 867512 examples: 0.380\n",
            "batch number: 3400\n",
            "Epoch 189: train_loss = 0.4013, train_accuracy = 0.9123, val_loss = 2.1062, val_accuracy = 0.3812\n",
            "Epoch 190: train_loss = 0.3870, train_accuracy = 0.9179, val_loss = 2.0337, val_accuracy = 0.3890\n",
            "Loss after 873884 examples: 0.322\n",
            "batch number: 3425\n",
            "Epoch 191: train_loss = 0.3854, train_accuracy = 0.9192, val_loss = 2.4111, val_accuracy = 0.3272\n",
            "Loss after 880270 examples: 0.372\n",
            "batch number: 3450\n",
            "Epoch 192: train_loss = 0.3782, train_accuracy = 0.9192, val_loss = 1.9200, val_accuracy = 0.4247\n",
            "Loss after 886642 examples: 0.359\n",
            "batch number: 3475\n",
            "Epoch 193: train_loss = 0.3634, train_accuracy = 0.9325, val_loss = 2.1253, val_accuracy = 0.3916\n",
            "Epoch 194: train_loss = 0.3653, train_accuracy = 0.9266, val_loss = 2.1012, val_accuracy = 0.3873\n",
            "Loss after 893028 examples: 0.292\n",
            "batch number: 3500\n",
            "Epoch 195: train_loss = 0.3422, train_accuracy = 0.9375, val_loss = 1.8934, val_accuracy = 0.4282\n",
            "Loss after 899414 examples: 0.383\n",
            "batch number: 3525\n",
            "Epoch 196: train_loss = 0.3410, train_accuracy = 0.9330, val_loss = 2.1450, val_accuracy = 0.4439\n",
            "Epoch 197: train_loss = 0.3535, train_accuracy = 0.9282, val_loss = 1.9786, val_accuracy = 0.4247\n",
            "Loss after 905786 examples: 0.377\n",
            "batch number: 3550\n",
            "Epoch 198: train_loss = 0.3499, train_accuracy = 0.9290, val_loss = 2.2489, val_accuracy = 0.3864\n",
            "Loss after 912172 examples: 0.331\n",
            "batch number: 3575\n",
            "Epoch 199: train_loss = 0.3292, train_accuracy = 0.9397, val_loss = 2.3804, val_accuracy = 0.3647\n",
            "Loss after 918558 examples: 0.349\n",
            "batch number: 3600\n",
            "Epoch 200: train_loss = 0.3335, train_accuracy = 0.9364, val_loss = 2.0924, val_accuracy = 0.4108\n",
            "Epoch 201: train_loss = 0.3240, train_accuracy = 0.9417, val_loss = 2.0394, val_accuracy = 0.4038\n",
            "Loss after 924930 examples: 0.361\n",
            "batch number: 3625\n",
            "Epoch 202: train_loss = 0.3200, train_accuracy = 0.9438, val_loss = 2.1219, val_accuracy = 0.4230\n",
            "Loss after 931316 examples: 0.330\n",
            "batch number: 3650\n",
            "Epoch 203: train_loss = 0.3106, train_accuracy = 0.9484, val_loss = 2.7560, val_accuracy = 0.3333\n",
            "Epoch 204: train_loss = 0.3126, train_accuracy = 0.9456, val_loss = 2.0185, val_accuracy = 0.4151\n",
            "Loss after 937688 examples: 0.274\n",
            "batch number: 3675\n",
            "Epoch 205: train_loss = 0.3135, train_accuracy = 0.9458, val_loss = 2.2453, val_accuracy = 0.3838\n",
            "Loss after 944074 examples: 0.336\n",
            "batch number: 3700\n",
            "Epoch 206: train_loss = 0.3231, train_accuracy = 0.9388, val_loss = 2.0615, val_accuracy = 0.4169\n",
            "Loss after 950460 examples: 0.322\n",
            "batch number: 3725\n",
            "Epoch 207: train_loss = 0.3080, train_accuracy = 0.9454, val_loss = 2.0689, val_accuracy = 0.4073\n",
            "Epoch 208: train_loss = 0.2879, train_accuracy = 0.9530, val_loss = 2.2324, val_accuracy = 0.4117\n",
            "Loss after 956832 examples: 0.260\n",
            "batch number: 3750\n",
            "Epoch 209: train_loss = 0.2871, train_accuracy = 0.9519, val_loss = 2.4842, val_accuracy = 0.3647\n",
            "Loss after 963218 examples: 0.295\n",
            "batch number: 3775\n",
            "Epoch 210: train_loss = 0.2910, train_accuracy = 0.9515, val_loss = 2.3431, val_accuracy = 0.3786\n",
            "Epoch 211: train_loss = 0.2942, train_accuracy = 0.9460, val_loss = 2.6859, val_accuracy = 0.3647\n",
            "Loss after 969590 examples: 0.320\n",
            "batch number: 3800\n",
            "Epoch 212: train_loss = 0.3050, train_accuracy = 0.9414, val_loss = 2.5615, val_accuracy = 0.3768\n",
            "Loss after 975976 examples: 0.284\n",
            "batch number: 3825\n",
            "Epoch 213: train_loss = 0.2938, train_accuracy = 0.9462, val_loss = 2.0889, val_accuracy = 0.4021\n",
            "Loss after 982362 examples: 0.344\n",
            "batch number: 3850\n",
            "Epoch 214: train_loss = 0.2909, train_accuracy = 0.9478, val_loss = 2.1223, val_accuracy = 0.4247\n",
            "Epoch 215: train_loss = 0.2820, train_accuracy = 0.9512, val_loss = 2.4128, val_accuracy = 0.3899\n",
            "Loss after 988734 examples: 0.277\n",
            "batch number: 3875\n",
            "Epoch 216: train_loss = 0.2813, train_accuracy = 0.9497, val_loss = 2.5818, val_accuracy = 0.3481\n",
            "Loss after 995120 examples: 0.238\n",
            "batch number: 3900\n",
            "Epoch 217: train_loss = 0.2871, train_accuracy = 0.9471, val_loss = 2.0586, val_accuracy = 0.4195\n",
            "Loss after 1001492 examples: 0.242\n",
            "batch number: 3925\n",
            "Epoch 218: train_loss = 0.2749, train_accuracy = 0.9534, val_loss = 2.2305, val_accuracy = 0.3908\n",
            "Epoch 219: train_loss = 0.2620, train_accuracy = 0.9580, val_loss = 2.2100, val_accuracy = 0.4160\n",
            "Loss after 1007878 examples: 0.252\n",
            "batch number: 3950\n",
            "Epoch 220: train_loss = 0.2547, train_accuracy = 0.9580, val_loss = 2.2309, val_accuracy = 0.3995\n",
            "Loss after 1014264 examples: 0.322\n",
            "batch number: 3975\n",
            "Epoch 221: train_loss = 0.2728, train_accuracy = 0.9493, val_loss = 2.6328, val_accuracy = 0.3681\n",
            "Epoch 222: train_loss = 0.2637, train_accuracy = 0.9565, val_loss = 2.2117, val_accuracy = 0.4178\n",
            "Loss after 1020636 examples: 0.264\n",
            "batch number: 4000\n",
            "Epoch 223: train_loss = 0.2540, train_accuracy = 0.9580, val_loss = 2.5544, val_accuracy = 0.3542\n",
            "Loss after 1027022 examples: 0.231\n",
            "batch number: 4025\n",
            "Epoch 224: train_loss = 0.2468, train_accuracy = 0.9617, val_loss = 3.2735, val_accuracy = 0.3386\n",
            "Loss after 1033408 examples: 0.204\n",
            "batch number: 4050\n",
            "Epoch 225: train_loss = 0.2573, train_accuracy = 0.9536, val_loss = 2.4020, val_accuracy = 0.3795\n",
            "Epoch 226: train_loss = 0.2400, train_accuracy = 0.9628, val_loss = 2.4972, val_accuracy = 0.3586\n",
            "Loss after 1039780 examples: 0.247\n",
            "batch number: 4075\n",
            "Epoch 227: train_loss = 0.2322, train_accuracy = 0.9623, val_loss = 2.1460, val_accuracy = 0.4230\n",
            "Loss after 1046166 examples: 0.199\n",
            "batch number: 4100\n",
            "Epoch 228: train_loss = 0.2215, train_accuracy = 0.9682, val_loss = 2.2764, val_accuracy = 0.4003\n",
            "Epoch 229: train_loss = 0.2423, train_accuracy = 0.9613, val_loss = 2.6770, val_accuracy = 0.3525\n",
            "Loss after 1052538 examples: 0.263\n",
            "batch number: 4125\n",
            "Epoch 230: train_loss = 0.2450, train_accuracy = 0.9584, val_loss = 2.3012, val_accuracy = 0.4169\n",
            "Loss after 1058924 examples: 0.266\n",
            "batch number: 4150\n",
            "Epoch 231: train_loss = 0.2353, train_accuracy = 0.9628, val_loss = 2.2008, val_accuracy = 0.4021\n",
            "Loss after 1065310 examples: 0.222\n",
            "batch number: 4175\n",
            "Epoch 232: train_loss = 0.2236, train_accuracy = 0.9650, val_loss = 2.3479, val_accuracy = 0.3873\n",
            "Epoch 233: train_loss = 0.2256, train_accuracy = 0.9643, val_loss = 2.2153, val_accuracy = 0.4021\n",
            "Loss after 1071682 examples: 0.249\n",
            "batch number: 4200\n",
            "Epoch 234: train_loss = 0.2239, train_accuracy = 0.9656, val_loss = 2.1931, val_accuracy = 0.4317\n",
            "Loss after 1078068 examples: 0.262\n",
            "batch number: 4225\n",
            "Epoch 235: train_loss = 0.2187, train_accuracy = 0.9658, val_loss = 2.3002, val_accuracy = 0.4273\n",
            "Epoch 236: train_loss = 0.2144, train_accuracy = 0.9660, val_loss = 2.1306, val_accuracy = 0.4352\n",
            "Loss after 1084440 examples: 0.192\n",
            "batch number: 4250\n",
            "Epoch 237: train_loss = 0.2156, train_accuracy = 0.9643, val_loss = 3.3909, val_accuracy = 0.3325\n",
            "Loss after 1090826 examples: 0.213\n",
            "batch number: 4275\n",
            "Epoch 238: train_loss = 0.2079, train_accuracy = 0.9665, val_loss = 2.3103, val_accuracy = 0.3838\n",
            "Loss after 1097212 examples: 0.194\n",
            "batch number: 4300\n",
            "Epoch 239: train_loss = 0.2147, train_accuracy = 0.9623, val_loss = 2.1320, val_accuracy = 0.4369\n",
            "Epoch 240: train_loss = 0.1982, train_accuracy = 0.9704, val_loss = 2.4216, val_accuracy = 0.3673\n",
            "Loss after 1103584 examples: 0.175\n",
            "batch number: 4325\n",
            "Epoch 241: train_loss = 0.2028, train_accuracy = 0.9676, val_loss = 3.0119, val_accuracy = 0.3264\n",
            "Loss after 1109970 examples: 0.212\n",
            "batch number: 4350\n",
            "Epoch 242: train_loss = 0.2038, train_accuracy = 0.9660, val_loss = 2.5559, val_accuracy = 0.4073\n",
            "Loss after 1116342 examples: 0.203\n",
            "batch number: 4375\n",
            "Epoch 243: train_loss = 0.1956, train_accuracy = 0.9704, val_loss = 2.1865, val_accuracy = 0.4238\n",
            "Epoch 244: train_loss = 0.1799, train_accuracy = 0.9728, val_loss = 2.2491, val_accuracy = 0.4212\n",
            "Loss after 1122728 examples: 0.169\n",
            "batch number: 4400\n",
            "Epoch 245: train_loss = 0.1812, train_accuracy = 0.9728, val_loss = 2.3191, val_accuracy = 0.4169\n",
            "Loss after 1129114 examples: 0.184\n",
            "batch number: 4425\n",
            "Epoch 246: train_loss = 0.1844, train_accuracy = 0.9708, val_loss = 2.5565, val_accuracy = 0.3969\n",
            "Epoch 247: train_loss = 0.2139, train_accuracy = 0.9613, val_loss = 2.5068, val_accuracy = 0.3951\n",
            "Loss after 1135486 examples: 0.188\n",
            "batch number: 4450\n",
            "Epoch 248: train_loss = 0.1889, train_accuracy = 0.9697, val_loss = 2.6367, val_accuracy = 0.3925\n",
            "Loss after 1141872 examples: 0.182\n",
            "batch number: 4475\n",
            "Epoch 249: train_loss = 0.1948, train_accuracy = 0.9695, val_loss = 2.7395, val_accuracy = 0.3916\n",
            "Loss after 1148258 examples: 0.212\n",
            "batch number: 4500\n",
            "Epoch 250: train_loss = 0.2177, train_accuracy = 0.9552, val_loss = 2.5849, val_accuracy = 0.3873\n",
            "Accuracy of the model on the 1149 test images: 38.729330%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>loss</td><td>██▇▇▇▇▇▇▇▆▅▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▂▂▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>train_loss</td><td>██▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▃▃▂▂▆▆▆▆▅▇▇▅▅█▇█▃▇▇█▇▇▆▇▆▇▆▆▇▄▆▆▄▆▇▄▇▆</td></tr><tr><td>val_loss</td><td>▃▃▃▃▁▃▁▁▁▁▁▂▂▁▂▂▂▂▂▃▃▄▃▆▆▃▃▃▄▄▆▄█▄▇█▅▅▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>249</td></tr><tr><td>loss</td><td>0.21194</td></tr><tr><td>test_accuracy</td><td>0.38729</td></tr><tr><td>train_accuracy</td><td>0.95516</td></tr><tr><td>train_loss</td><td>0.21773</td></tr><tr><td>val_accuracy</td><td>0.38729</td></tr><tr><td>val_loss</td><td>2.58485</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">MiniDenseNet</strong> at: <a href='https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_better_eval/runs/je99a24g' target=\"_blank\">https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_better_eval/runs/je99a24g</a><br> View project at: <a href='https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_better_eval' target=\"_blank\">https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_better_eval</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250528_082027-je99a24g/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "id": "PhusPwNHkvAx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b62f87b2-f01c-4699-f6d4-2348a2515f19"
      },
      "id": "PhusPwNHkvAx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9dbcb31bd76b4ba492bed4578126cf55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8952809bfb3a416f830985857216cd78",
              "IPY_MODEL_a9b5b5c9e0a849dbab684722b876dca7",
              "IPY_MODEL_e0980a635bb94fafb478a0c01986a0af"
            ],
            "layout": "IPY_MODEL_b666a67396a24df280b79cf505dad8b2"
          }
        },
        "8952809bfb3a416f830985857216cd78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d31a01c2155444aae445ab268972085",
            "placeholder": "​",
            "style": "IPY_MODEL_814310b2af5d4217b8a22016b314865a",
            "value": "100%"
          }
        },
        "a9b5b5c9e0a849dbab684722b876dca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51a03096621f414ca6b18dfe271fe546",
            "max": 250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a813366a06354905b7124645a53ebdb6",
            "value": 250
          }
        },
        "e0980a635bb94fafb478a0c01986a0af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b48fec27b0b242ffadf5c6fad6297db6",
            "placeholder": "​",
            "style": "IPY_MODEL_3bebdd50df804db8b7c6a76f14e300f5",
            "value": " 250/250 [13:29&lt;00:00,  3.21s/it]"
          }
        },
        "b666a67396a24df280b79cf505dad8b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d31a01c2155444aae445ab268972085": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "814310b2af5d4217b8a22016b314865a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51a03096621f414ca6b18dfe271fe546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a813366a06354905b7124645a53ebdb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b48fec27b0b242ffadf5c6fad6297db6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bebdd50df804db8b7c6a76f14e300f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}