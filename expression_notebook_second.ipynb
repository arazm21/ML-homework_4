{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arazm21/ML-homework_4/blob/main/expression_notebook_second.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# loading the data and organising it"
      ],
      "metadata": {
        "id": "ShlkPaeoBQ3k"
      },
      "id": "ShlkPaeoBQ3k"
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "! mkdir ~/.kaggle\n",
        "!cp /content/drive/MyDrive/ColabNotebooks/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
        "! unzip challenges-in-representation-learning-facial-expression-recognition-challenge"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNNvBwljBQFE",
        "outputId": "02eba96d-fd2b-4f21-be10-4d635b5b12ef"
      },
      "id": "dNNvBwljBQFE",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Downloading challenges-in-representation-learning-facial-expression-recognition-challenge.zip to /content\n",
            " 93% 266M/285M [00:01<00:00, 114MB/s]\n",
            "100% 285M/285M [00:01<00:00, 159MB/s]\n",
            "Archive:  challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
            "  inflating: example_submission.csv  \n",
            "  inflating: fer2013.tar.gz          \n",
            "  inflating: icml_face_data.csv      \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fXPkihKllSZ",
        "outputId": "48c69e55-b6d6-4067-c0f4-5d9a68386bd7"
      },
      "id": "9fXPkihKllSZ",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.13.2)\n",
            "Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # Main PyTorch Library\n",
        "from torch import nn # Used for creating the layers and loss function\n",
        "from torch.optim import Adam # Adam Optimizer\n",
        "import torchvision.transforms as transforms # Transform function used to modify and preprocess all the images\n",
        "from torch.utils.data import Dataset, DataLoader # Dataset class and DataLoader for creating the objects\n",
        "from sklearn.preprocessing import LabelEncoder # Label Encoder to encode the classes from strings to numbers\n",
        "import matplotlib.pyplot as plt # Used for visualizing the images and plotting the training progress\n",
        "from PIL import Image # Used to read the images from the directory\n",
        "import pandas as pd # Used to read/create dataframes (csv) and process tabular data\n",
        "import numpy as np # preprocessing and numerical/mathematical operations\n",
        "import os # Used to read the images path from the directory\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # detect the GPU if any, if not use CPU, change cuda to mps if you have a mac\n",
        "print(\"Device available: \", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xib5nVmSLH0o",
        "outputId": "cff50f62-aece-4785-cd93-afe22d95cb9b"
      },
      "id": "xib5nVmSLH0o",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device available:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b5Ptu8H4Lzx6"
      },
      "id": "b5Ptu8H4Lzx6",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, Subset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "class ExpressionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, csv_file, indices=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "\n",
        "        if indices is not None:\n",
        "            self.data = self.data.iloc[indices].reset_index(drop=True)\n",
        "\n",
        "        self.images = self.data['pixels'].apply(\n",
        "            lambda x: np.fromstring(x, sep=' ', dtype=np.uint8).reshape(48, 48)\n",
        "        )\n",
        "        self.images = torch.tensor(np.stack(self.images.values), dtype=torch.float32).unsqueeze(1) / 255.0\n",
        "        self.labels = torch.tensor(self.data['emotion'].values, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx], self.labels[idx]\n",
        "\n",
        "\n",
        "def get_data(csv_file=\"train.csv\", slice=5, train=True, val_ratio=0.2, random_state=42):\n",
        "    # Load full train.csv data\n",
        "    full_data = pd.read_csv(csv_file)\n",
        "    indices = list(range(len(full_data)))\n",
        "\n",
        "    # Stratified split indices for train/validation\n",
        "    train_indices, val_indices = train_test_split(\n",
        "        indices,\n",
        "        test_size=val_ratio,\n",
        "        stratify=full_data['emotion'],\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Select which indices to use\n",
        "    selected_indices = train_indices if train else val_indices\n",
        "\n",
        "    # Create dataset with selected indices\n",
        "    dataset = ExpressionDataset(csv_file, indices=selected_indices)\n",
        "\n",
        "    # Slice dataset if requested\n",
        "    sliced_indices = list(range(0, len(dataset), slice))\n",
        "    return Subset(dataset, sliced_indices)\n",
        "\n",
        "\n",
        "def make_loader(dataset, batch_size):\n",
        "    loader = DataLoader(dataset=dataset,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=True,\n",
        "                        pin_memory=True,\n",
        "                        num_workers=2)\n",
        "    return loader\n"
      ],
      "metadata": {
        "id": "D1ye0F1iHqSC"
      },
      "id": "D1ye0F1iHqSC",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test that loading was ok"
      ],
      "metadata": {
        "id": "RsFhOzV_PHxI"
      },
      "id": "RsFhOzV_PHxI"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and create loader\n",
        "dataset = get_data(slice=1, train=False)\n",
        "loader = make_loader(dataset, batch_size=3)\n",
        "\n",
        "# Get a batch\n",
        "images, labels = next(iter(loader))\n",
        "\n",
        "# Class names from FER2013\n",
        "emotion_names = [\n",
        "    \"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"\n",
        "]\n",
        "\n",
        "# Plot the first 3 images\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(3):\n",
        "    plt.subplot(1, 3, i + 1)\n",
        "    plt.imshow(images[i][0], cmap='gray')\n",
        "    plt.title(f\"Label: {emotion_names[labels[i].item()]}\")\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "NvgplaWYHJX6",
        "outputId": "9b2545fe-a974-4ffb-8a56-1da0ea2f7bc9"
      },
      "id": "NvgplaWYHJX6",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# connecting WANDB"
      ],
      "metadata": {
        "id": "XhwXYgieSf7u"
      },
      "id": "XhwXYgieSf7u"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Ensure deterministic behavior\n",
        "torch.backends.cudnn.deterministic = True\n",
        "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
        "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
        "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
        "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "zt2tymF2Se4p"
      },
      "id": "zt2tymF2Se4p",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "l2Op72b3SsY1",
        "outputId": "6fb9af4b-da80-405e-f064-bc730ac2f8ae"
      },
      "id": "l2Op72b3SsY1",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marazm21\u001b[0m (\u001b[33marazm21-free-university-of-tbilisi-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ymLc1hz_XE5W"
      },
      "id": "ymLc1hz_XE5W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# different attempted architectures"
      ],
      "metadata": {
        "id": "FjvVv9RPXFbN"
      },
      "id": "FjvVv9RPXFbN"
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.nn as nn\n",
        "\n",
        "# class ConvNet_super_simple(nn.Module):\n",
        "#     def __init__(self, kernels, classes=7):\n",
        "#         super(ConvNet_super_simple, self).__init__()\n",
        "\n",
        "#         self.layer1 = nn.Sequential(\n",
        "#             nn.Conv2d(1, kernels[0], kernel_size=5, stride=1, padding=2),\n",
        "#             nn.ReLU(),\n",
        "#             nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "#         )\n",
        "#         self.layer2 = nn.Sequential(\n",
        "#             nn.Conv2d(kernels[0], kernels[1], kernel_size=5, stride=1, padding=2),\n",
        "#             nn.ReLU(),\n",
        "#             nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "#         )\n",
        "\n",
        "#         # Assuming 48x48 input, after two 2x2 poolings -> 48/2/2 = 12x12\n",
        "#         self.fc = nn.Linear(12 * 12 * kernels[1], classes)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         out = self.layer1(x)\n",
        "#         out = self.layer2(out)\n",
        "#         out = out.view(out.size(0), -1)\n",
        "#         out = self.fc(out)\n",
        "#         return out\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ConvNet_Improved(nn.Module):\n",
        "    def __init__(self, kernels, classes=7):\n",
        "        super(ConvNet_Improved, self).__init__()\n",
        "\n",
        "        # First conv block\n",
        "        self.conv1 = nn.Conv2d(1, kernels[0], kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(kernels[0])\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Second conv block\n",
        "        self.conv2 = nn.Conv2d(kernels[0], kernels[1], kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(kernels[1])\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Third conv block\n",
        "        self.conv3 = nn.Conv2d(kernels[1], kernels[2], kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(kernels[2])\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.dropout3 = nn.Dropout(0.4)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Assuming 48x48 input → 3 poolings: 48 → 24 → 12 → 6\n",
        "        self.flattened_dim = 6 * 6 * kernels[2]\n",
        "        self.fc = nn.Linear(self.flattened_dim, classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.dropout1(self.relu1(self.bn1(self.conv1(x)))))\n",
        "        x = self.pool2(self.dropout2(self.relu2(self.bn2(self.conv2(x)))))\n",
        "        x = self.pool3(self.dropout3(self.relu3(self.bn3(self.conv3(x)))))\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "RaFvctrZTf1t"
      },
      "id": "RaFvctrZTf1t",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## resnet"
      ],
      "metadata": {
        "id": "cumrZOH9Sj1A"
      },
      "id": "cumrZOH9Sj1A"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsample=False, dropout_rate=0.2):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        stride = 2 if downsample else 1\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if downsample or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "        self.dropout = nn.Dropout2d(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.shortcut(x)\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out = self.dropout(out)  # ✅ Dropout after residual addition\n",
        "        out += identity\n",
        "        out = F.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class SimpleResNet15(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_classes=7, dropout_rate=0.34):\n",
        "        super(SimpleResNet15, self).__init__()\n",
        "\n",
        "        self.entry = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            ResidualBlock(64, 128, downsample=True, dropout_rate=dropout_rate),\n",
        "            ResidualBlock(128, 256, downsample=True, dropout_rate=dropout_rate),\n",
        "            ResidualBlock(256, 512, downsample=True, dropout_rate=dropout_rate),\n",
        "            ResidualBlock(512, 1024, downsample=True, dropout_rate=dropout_rate),\n",
        "            ResidualBlock(1024, 2048, downsample=True, dropout_rate=dropout_rate),\n",
        "            ResidualBlock(2048, 2048, downsample=True, dropout_rate=dropout_rate),\n",
        "            ResidualBlock(2048, 1024, downsample=True, dropout_rate=dropout_rate),\n",
        "            ResidualBlock(1024, 512, downsample=True, dropout_rate=dropout_rate),\n",
        "            ResidualBlock(512, 256, downsample=True, dropout_rate=dropout_rate),\n",
        "\n",
        "            ResidualBlock(512, 256, downsample=False, dropout_rate=dropout_rate),\n",
        "            ResidualBlock(256, 128, downsample=False, dropout_rate=dropout_rate),\n",
        "            ResidualBlock(128, 64, downsample=False, dropout_rate=dropout_rate),\n",
        "            ResidualBlock(64, 32, downsample=False, dropout_rate=dropout_rate)\n",
        "        )\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.entry(x)\n",
        "        x = self.layers(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)\n"
      ],
      "metadata": {
        "id": "PFYKchqhXTSt"
      },
      "id": "PFYKchqhXTSt",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## googlenet(mini)"
      ],
      "metadata": {
        "id": "ltk-bzVKSnDU"
      },
      "id": "ltk-bzVKSnDU"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MiniInception(nn.Module):\n",
        "    def __init__(self, in_ch, c1, c3red, c3, pool_proj):\n",
        "        super().__init__()\n",
        "        # 1×1 branch\n",
        "        self.b1 = nn.Conv2d(in_ch, c1, kernel_size=1)\n",
        "        # 1×1 → 3×3 branch\n",
        "        self.b2_1 = nn.Conv2d(in_ch, c3red, kernel_size=1)\n",
        "        self.b2_2 = nn.Conv2d(c3red, c3,   kernel_size=3, padding=1)\n",
        "        # pool → 1×1 branch\n",
        "        self.b3_pool = nn.MaxPool2d(3, stride=1, padding=1)\n",
        "        self.b3_proj = nn.Conv2d(in_ch, pool_proj, kernel_size=1)\n",
        "\n",
        "        self.bn = nn.BatchNorm2d(c1 + c3 + pool_proj)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b1 = self.b1(x)\n",
        "        b2 = self.b2_2(F.relu(self.b2_1(x)))\n",
        "        b3 = self.b3_proj(self.b3_pool(x))\n",
        "        out = torch.cat([b1, b2, b3], dim=1)\n",
        "        return F.relu(self.bn(out))\n",
        "\n",
        "\n",
        "class MiniGoogLeNet(nn.Module):\n",
        "    def __init__(self, num_classes=7, aux_on=True):\n",
        "        super().__init__()\n",
        "        self.aux_on = aux_on\n",
        "\n",
        "        # ---- stem ----\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32), nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)  # 48→24\n",
        "        )\n",
        "\n",
        "        # ---- two Inception blocks ----\n",
        "        self.inc1 = MiniInception(32, c1=16, c3red=16, c3=24, pool_proj=16)  # outputs 56\n",
        "        self.inc2 = MiniInception(56, c1=32, c3red=24, c3=32, pool_proj=24)  # outputs 88\n",
        "\n",
        "        # auxiliary head (after inc1)\n",
        "        if aux_on:\n",
        "            self.aux = nn.Sequential(\n",
        "                nn.AdaptiveAvgPool2d( (4,4) ),\n",
        "                nn.Conv2d(56, 32, 1), nn.ReLU(),\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(32*4*4, 128), nn.ReLU(), nn.Dropout(0.5),\n",
        "                nn.Linear(128, num_classes)\n",
        "            )\n",
        "\n",
        "        # ---- classifier head ----\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc   = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(88, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)            # → [B,32,24,24]\n",
        "        x1 = self.inc1(x)           # → [B,56,24,24]\n",
        "\n",
        "        if self.training and self.aux_on:\n",
        "            aux_out = self.aux(x1)\n",
        "\n",
        "        x2 = F.max_pool2d(x1, 2, 2) # → [B,56,12,12]\n",
        "        x2 = self.inc2(x2)          # → [B,88,12,12]\n",
        "\n",
        "        x3 = self.pool(x2)          # → [B,88,1,1]\n",
        "        main_out = self.fc(x3)      # → [B,num_classes]\n",
        "\n",
        "        return (main_out, aux_out) if (self.training and self.aux_on) else main_out\n"
      ],
      "metadata": {
        "id": "2ydG-CJ4SsQ_"
      },
      "id": "2ydG-CJ4SsQ_",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# geting everything ready"
      ],
      "metadata": {
        "id": "zaVbntQmXODJ"
      },
      "id": "zaVbntQmXODJ"
    },
    {
      "cell_type": "code",
      "source": [
        "def make(config):\n",
        "    # Make the data\n",
        "    train_dataset = get_data(train=True)\n",
        "    test_dataset = get_data(train=False)\n",
        "    train_loader = make_loader(train_dataset, batch_size=config.batch_size)\n",
        "    test_loader = make_loader(test_dataset, batch_size=config.batch_size)\n",
        "\n",
        "    # Make the model\n",
        "    model = SimpleResNet15().to(device)\n",
        "\n",
        "    # Make the loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "    return model, train_loader, test_loader, criterion, optimizer"
      ],
      "metadata": {
        "id": "4GOnNEKyT1v2"
      },
      "id": "4GOnNEKyT1v2",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_log(loss, example_ct, epoch):\n",
        "    # Where the magic happens\n",
        "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
        "    print(f\"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}\")"
      ],
      "metadata": {
        "id": "Jwbd9gvXUp4R"
      },
      "id": "Jwbd9gvXUp4R",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## early stop training"
      ],
      "metadata": {
        "id": "6Vih9mc96ns6"
      },
      "id": "6Vih9mc96ns6"
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, min_delta=0.0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best_loss = float('inf')\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "\n",
        "def validate(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss /= total\n",
        "    val_acc = correct / total\n",
        "    return val_loss, val_acc\n",
        "\n",
        "def train(model, train_loader, val_loader, criterion, optimizer, config):\n",
        "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "\n",
        "    early_stopper = EarlyStopping(patience=15, min_delta=0.001)\n",
        "\n",
        "    example_ct = 0\n",
        "    batch_ct = 0\n",
        "    for epoch in tqdm(range(config.epochs)):\n",
        "        model.train()\n",
        "        running_correct = 0\n",
        "        running_total = 0\n",
        "\n",
        "        for _, (images, labels) in enumerate(train_loader):\n",
        "            loss, batch_correct, batch_total = train_batch(images, labels, model, optimizer, criterion)\n",
        "            example_ct += len(images)\n",
        "            batch_ct += 1\n",
        "\n",
        "            running_correct += batch_correct\n",
        "            running_total += batch_total\n",
        "\n",
        "            if ((batch_ct + 1) % 25) == 0:\n",
        "                train_log(loss, example_ct, epoch)\n",
        "                print(f\"batch number: {batch_ct + 1}\")\n",
        "\n",
        "        train_acc = running_correct / running_total\n",
        "\n",
        "        # ⏱️ Validate at the end of the epoch\n",
        "        val_loss, val_acc = validate(model, val_loader, criterion)\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_accuracy\": val_acc,\n",
        "            \"train_accuracy\": train_acc\n",
        "        })\n",
        "        print(f\"Epoch {epoch + 1}: val_loss = {val_loss:.4f}, val_acc = {val_acc:.4f}, train_acc = {train_acc:.4f}\")\n",
        "\n",
        "        # Check early stopping\n",
        "        early_stopper(val_loss)\n",
        "        if early_stopper.early_stop:\n",
        "            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
        "            break\n",
        "def train_batch(images, labels, model, optimizer, criterion):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    total = labels.size(0)\n",
        "\n",
        "    return loss, correct, total"
      ],
      "metadata": {
        "id": "2gDrRJB56ihi"
      },
      "id": "2gDrRJB56ihi",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## normal training"
      ],
      "metadata": {
        "id": "Ts0xewao6rsq"
      },
      "id": "Ts0xewao6rsq"
    },
    {
      "cell_type": "code",
      "source": [
        "# def train(model, loader, criterion, optimizer, config):\n",
        "#     # Tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
        "#     wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "\n",
        "#     # Run training and track with wandb\n",
        "#     total_batches = len(loader) * config.epochs\n",
        "#     example_ct = 0  # number of examples seen\n",
        "#     batch_ct = 0\n",
        "#     for epoch in tqdm(range(config.epochs)):\n",
        "#         for _, (images, labels) in enumerate(loader):\n",
        "\n",
        "#             loss = train_batch(images, labels, model, optimizer, criterion)\n",
        "#             example_ct +=  len(images)\n",
        "#             batch_ct += 1\n",
        "\n",
        "#             # Report metrics every 25th batch\n",
        "#             if ((batch_ct + 1) % 25) == 0:\n",
        "#                 train_log(loss, example_ct, epoch)\n",
        "#                 print(f\"batch number: {batch_ct + 1}\")\n",
        "def validate(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss /= total\n",
        "    val_acc = correct / total\n",
        "    return val_loss, val_acc\n",
        "def train(model, train_loader, val_loader, criterion, optimizer, config):\n",
        "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "\n",
        "    example_ct = 0\n",
        "    batch_ct = 0\n",
        "    for epoch in tqdm(range(config.epochs)):\n",
        "        model.train()\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "        train_loss_accumulator = 0.0\n",
        "\n",
        "        for _, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            example_ct += len(images)\n",
        "            batch_ct += 1\n",
        "\n",
        "            # Calculate training accuracy\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Accumulate loss for the epoch\n",
        "            train_loss_accumulator += loss.item() * images.size(0)\n",
        "\n",
        "            # Report metrics every 25th batch\n",
        "            if ((batch_ct + 1) % 25) == 0:\n",
        "                train_log(loss, example_ct, epoch)\n",
        "                print(f\"batch number: {batch_ct + 1}\")\n",
        "\n",
        "        # Final training metrics for the epoch\n",
        "        train_loss = train_loss_accumulator / train_total\n",
        "        train_acc = train_correct / train_total\n",
        "\n",
        "        # ⏱️ Validation step\n",
        "        val_loss, val_acc = validate(model, val_loader, criterion)\n",
        "\n",
        "        # Log both train & val metrics\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_accuracy\": train_acc,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_accuracy\": val_acc\n",
        "        })\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}: \"\n",
        "              f\"train_loss = {train_loss:.4f}, train_accuracy = {train_acc:.4f}, \"\n",
        "              f\"val_loss = {val_loss:.4f}, val_accuracy = {val_acc:.4f}\")\n",
        "def train_batch(images, labels, model, optimizer, criterion):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    # Forward pass ➡\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Backward pass ⬅\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Step with optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss\n",
        "\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "\n",
        "    # Run the model on some test examples\n",
        "    with torch.no_grad():\n",
        "        correct, total = 0, 0\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        print(f\"Accuracy of the model on the {total} \" +\n",
        "              f\"test images: {correct / total:%}\")\n",
        "\n",
        "        wandb.log({\"test_accuracy\": correct / total})\n",
        "\n",
        "    # Save the model in the exchangeable ONNX format\n",
        "    torch.onnx.export(model, images, \"model.onnx\")\n",
        "    wandb.save(\"model.onnx\")"
      ],
      "metadata": {
        "id": "F3VQ1HxlUk6V"
      },
      "id": "F3VQ1HxlUk6V",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JYjjS-iHUuUG"
      },
      "id": "JYjjS-iHUuUG",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_pipeline(hyperparameters):\n",
        "\n",
        "    # tell wandb to get started\n",
        "    with wandb.init(project=\"expression_dataset_better_eval\",\n",
        "                    config=hyperparameters,\n",
        "                    name = \"resnet_different_dropout\"):\n",
        "      # access all HPs through wandb.config, so logging matches execution!\n",
        "      config = wandb.config\n",
        "\n",
        "      # make the model, data, and optimization problem\n",
        "      model, train_loader, test_loader, criterion, optimizer = make(config)\n",
        "      print(model)\n",
        "\n",
        "      # and use them to train the model\n",
        "      # train(model, train_loader, criterion, optimizer, config)\n",
        "\n",
        "      # # and test its final performance\n",
        "      # test(model, test_loader)\n",
        "      train(model, train_loader, test_loader, criterion, optimizer, config)\n",
        "      test(model, test_loader)  # final test; you can use actual test set here if available\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "cEsYfYCkUbYw"
      },
      "id": "cEsYfYCkUbYw",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = dict(\n",
        "    epochs=250,\n",
        "    classes=7,\n",
        "    #kernels=[32, 64, 128],\n",
        "    batch_size=256,\n",
        "    learning_rate=1e-4,\n",
        "    dataset=\"Facial Expression Recognition\",\n",
        "    architecture=\"resnet_different_dropout\")"
      ],
      "metadata": {
        "id": "GoXMnqIWY9fa"
      },
      "id": "GoXMnqIWY9fa",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train!"
      ],
      "metadata": {
        "id": "MQvkFnUNxXls"
      },
      "id": "MQvkFnUNxXls"
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_pipeline(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4779a00f57b74acd9b713c4528d90f61",
            "a02a9fdcc1b640809e83c110de963081",
            "62e816eb51e3432aba607f0be80bde08",
            "7108e3b5bc524042a4f2ff2e54940f75",
            "a55c5efa086748acb057a2bf04a242bb",
            "e7c869ecb6a340bb83000655530d6bc6",
            "106bab41c4b245179e678a06bce1269e",
            "bab31aa725e44bdca3d5c642333f76e1",
            "0039f4d93b1943da8ed63a68eda29699",
            "9d4e93a8158f43e6b19b65228fa5b8c2",
            "081e1e6586a144afae009564b0c28328"
          ]
        },
        "id": "MifXx_iuXfLi",
        "outputId": "5a36df8c-985a-48c1-9d97-edc2834ecc26"
      },
      "id": "MifXx_iuXfLi",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250527_092523-uvof7xdp</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_better_eval/runs/uvof7xdp' target=\"_blank\">resnet_different_dropout</a></strong> to <a href='https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_better_eval' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_better_eval' target=\"_blank\">https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_better_eval</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_better_eval/runs/uvof7xdp' target=\"_blank\">https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_better_eval/runs/uvof7xdp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleResNet15(\n",
            "  (entry): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (layers): Sequential(\n",
            "    (0): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
            "    )\n",
            "    (1): ResidualBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
            "    )\n",
            "    (2): ResidualBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
            "    )\n",
            "    (3): ResidualBlock(\n",
            "      (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
            "    )\n",
            "    (4): ResidualBlock(\n",
            "      (conv1): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
            "    )\n",
            "    (5): ResidualBlock(\n",
            "      (conv1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
            "    )\n",
            "    (6): ResidualBlock(\n",
            "      (conv1): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
            "    )\n",
            "    (7): ResidualBlock(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
            "    )\n",
            "    (8): ResidualBlock(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
            "    )\n",
            "    (9): ResidualBlock(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
            "    )\n",
            "    (10): ResidualBlock(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
            "    )\n",
            "    (11): ResidualBlock(\n",
            "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
            "    )\n",
            "    (12): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (dropout): Dropout2d(p=0.3, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=32, out_features=7, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4779a00f57b74acd9b713c4528d90f61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-36-c668d6467768>\", line 19, in model_pipeline\n",
            "    train(model, train_loader, test_loader, criterion, optimizer, config)\n",
            "  File \"<ipython-input-35-6fb89abd278e>\", line 52, in train\n",
            "    loss, batch_correct, batch_total = train_batch(images, labels, model, optimizer, criterion)\n",
            "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-35-6fb89abd278e>\", line 83, in train_batch\n",
            "    outputs = model(images)\n",
            "              ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1845, in _call_impl\n",
            "    return inner()\n",
            "           ^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1793, in inner\n",
            "    result = forward_call(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-31-43892bc1c5ae>\", line 66, in forward\n",
            "    x = self.layers(x)\n",
            "        ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-31-43892bc1c5ae>\", line 25, in forward\n",
            "    identity = self.shortcut(x)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n",
            "    return F.conv2d(\n",
            "           ^^^^^^^^^\n",
            "RuntimeError: Given groups=1, weight of size [128, 64, 1, 1], expected input[256, 32, 48, 48] to have 64 channels, but got 32 channels instead\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">resnet_different_dropout</strong> at: <a href='https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_better_eval/runs/uvof7xdp' target=\"_blank\">https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_better_eval/runs/uvof7xdp</a><br> View project at: <a href='https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_better_eval' target=\"_blank\">https://wandb.ai/arazm21-free-university-of-tbilisi-/expression_dataset_better_eval</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250527_092523-uvof7xdp/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [128, 64, 1, 1], expected input[256, 32, 48, 48] to have 64 channels, but got 32 channels instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-9807c214ebcc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-c668d6467768>\u001b[0m in \u001b[0;36mmodel_pipeline\u001b[0;34m(hyperparameters)\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0;31m# # and test its final performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0;31m# test(model, test_loader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m       \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m       \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# final test; you can use actual test set here if available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-6fb89abd278e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, config)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mexample_ct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mbatch_ct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-6fb89abd278e>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(images, labels, model, optimizer, criterion)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1845\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1846\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m             \u001b[0;31m# run always called hooks if they have not already been run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36minner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1794\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m                 for hook_id, hook in (\n",
            "\u001b[0;32m<ipython-input-31-43892bc1c5ae>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-43892bc1c5ae>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [128, 64, 1, 1], expected input[256, 32, 48, 48] to have 64 channels, but got 32 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "id": "PhusPwNHkvAx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b62f87b2-f01c-4699-f6d4-2348a2515f19"
      },
      "id": "PhusPwNHkvAx",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4779a00f57b74acd9b713c4528d90f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a02a9fdcc1b640809e83c110de963081",
              "IPY_MODEL_62e816eb51e3432aba607f0be80bde08",
              "IPY_MODEL_7108e3b5bc524042a4f2ff2e54940f75"
            ],
            "layout": "IPY_MODEL_a55c5efa086748acb057a2bf04a242bb"
          }
        },
        "a02a9fdcc1b640809e83c110de963081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7c869ecb6a340bb83000655530d6bc6",
            "placeholder": "​",
            "style": "IPY_MODEL_106bab41c4b245179e678a06bce1269e",
            "value": "  0%"
          }
        },
        "62e816eb51e3432aba607f0be80bde08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bab31aa725e44bdca3d5c642333f76e1",
            "max": 250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0039f4d93b1943da8ed63a68eda29699",
            "value": 0
          }
        },
        "7108e3b5bc524042a4f2ff2e54940f75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d4e93a8158f43e6b19b65228fa5b8c2",
            "placeholder": "​",
            "style": "IPY_MODEL_081e1e6586a144afae009564b0c28328",
            "value": " 0/250 [00:00&lt;?, ?it/s]"
          }
        },
        "a55c5efa086748acb057a2bf04a242bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7c869ecb6a340bb83000655530d6bc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "106bab41c4b245179e678a06bce1269e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bab31aa725e44bdca3d5c642333f76e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0039f4d93b1943da8ed63a68eda29699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d4e93a8158f43e6b19b65228fa5b8c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "081e1e6586a144afae009564b0c28328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}